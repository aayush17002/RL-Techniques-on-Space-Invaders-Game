{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IIN5P24oT3T"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lpesrCn1kcwZ"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import imageio\n",
    "from tensorflow import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cyM1FV5oYcN"
   },
   "source": [
    "# Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZDdJGWpKkcr8"
   },
   "outputs": [],
   "source": [
    "MAX_EPSILON = 1\n",
    "MIN_EPSILON = 0.1\n",
    "EPSILON_MIN_ITER = 500000\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 32\n",
    "TAU = 0.08\n",
    "POST_PROCESS_IMAGE_SIZE = (105, 80, 1)\n",
    "DELAY_TRAINING = 50000\n",
    "NUM_FRAMES = 4\n",
    "GIF_RECORDING_FREQ = 100\n",
    "\n",
    "env = gym.make(\"SpaceInvaders-v0\")\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmCBoem4ocEF"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uiI_MBoakcmz"
   },
   "outputs": [],
   "source": [
    "class DQModel(keras.Model):\n",
    "    def __init__(self, hidden_size: int, num_actions: int, dueling: bool):\n",
    "        super(DQModel, self).__init__()\n",
    "        self.dueling = dueling\n",
    "        self.conv1 = keras.layers.Conv2D(16, (8, 8), (4, 4), activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(32, (4, 4), (2, 2), activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.adv_dense = keras.layers.Dense(hidden_size, activation='relu', kernel_initializer=keras.initializers.he_normal())\n",
    "        self.adv_out = keras.layers.Dense(num_actions, kernel_initializer=keras.initializers.he_normal())\n",
    "        if dueling:\n",
    "            self.v_dense = keras.layers.Dense(hidden_size, activation='relu', kernel_initializer=keras.initializers.he_normal())\n",
    "            self.v_out = keras.layers.Dense(1, kernel_initializer=keras.initializers.he_normal())\n",
    "            self.lambda_layer = keras.layers.Lambda(lambda x: x - tf.reduce_mean(x))\n",
    "            self.combine = keras.layers.Add()\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        adv = self.adv_dense(x)\n",
    "        adv = self.adv_out(adv)\n",
    "        if self.dueling:\n",
    "            v = self.v_dense(x)\n",
    "            v = self.v_out(v)\n",
    "            norm_adv = self.lambda_layer(adv)\n",
    "            combined = self.combine([v, norm_adv])\n",
    "            return combined\n",
    "        return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "187YKmMXkqBD"
   },
   "outputs": [],
   "source": [
    "primary_network = DQModel(256, num_actions, False)\n",
    "target_network = DQModel(256, num_actions, False)\n",
    "primary_network.compile(optimizer=keras.optimizers.Adam(), loss='mse')\n",
    "# make target_network = primary_network\n",
    "for t, e in zip(target_network.trainable_variables, primary_network.trainable_variables):\n",
    "    t.assign(e)\n",
    "\n",
    "primary_network.compile(optimizer=keras.optimizers.Adam(), loss=tf.keras.losses.Huber())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvfzIEKdogTP"
   },
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R-0_lgVUkp6_"
   },
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_memory):\n",
    "        self._max_memory = max_memory\n",
    "        self._actions = np.zeros(max_memory, dtype=np.int32)\n",
    "        self._rewards = np.zeros(max_memory, dtype=np.float32)\n",
    "        self._frames = np.zeros((POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], max_memory), dtype=np.float32)\n",
    "        self._terminal = np.zeros(max_memory, dtype=np.bool)\n",
    "        self._i = 0\n",
    "\n",
    "    def add_sample(self, frame, action, reward, terminal):\n",
    "        self._actions[self._i] = action\n",
    "        self._rewards[self._i] = reward\n",
    "        self._frames[:, :, self._i] = frame[:, :, 0]\n",
    "        self._terminal[self._i] = terminal\n",
    "        if self._i % (self._max_memory - 1) == 0 and self._i != 0:\n",
    "            self._i = BATCH_SIZE + NUM_FRAMES + 1\n",
    "        else:\n",
    "            self._i += 1\n",
    "\n",
    "    def sample(self):\n",
    "        if self._i < BATCH_SIZE + NUM_FRAMES + 1:\n",
    "            raise ValueError(\"Not enough memory to extract a batch\")\n",
    "        else:\n",
    "            rand_idxs = np.random.randint(NUM_FRAMES + 1, self._i, size=BATCH_SIZE)\n",
    "            states = np.zeros((BATCH_SIZE, POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES), dtype=np.float32)\n",
    "            next_states = np.zeros((BATCH_SIZE, POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES), dtype=np.float32)\n",
    "            for i, idx in enumerate(rand_idxs):\n",
    "                states[i] = self._frames[:, :, idx - 1 - NUM_FRAMES:idx - 1]\n",
    "                next_states[i] = self._frames[:, :, idx - NUM_FRAMES:idx]\n",
    "            return states, self._actions[rand_idxs], self._rewards[rand_idxs], next_states, self._terminal[rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LzYyYT8Hkp1n"
   },
   "outputs": [],
   "source": [
    "# memory = Memory(500000)\n",
    "memory = Memory(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1fbQgmfoj6v"
   },
   "source": [
    "# Extra Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1OeRLtSckpwS"
   },
   "outputs": [],
   "source": [
    "def image_preprocess(image, new_size=(105, 80)):\n",
    "    # convert to greyscale, resize and normalize the image\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image, new_size)\n",
    "    image = image / 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UnfeMJZSk88d"
   },
   "outputs": [],
   "source": [
    "def choose_action(state, primary_network, eps, step):\n",
    "    if step < DELAY_TRAINING:\n",
    "        return random.randint(0, num_actions - 1)\n",
    "    else:\n",
    "        if random.random() < eps:\n",
    "            return random.randint(0, num_actions - 1)\n",
    "        else:\n",
    "            return np.argmax(primary_network(tf.reshape(state, (1, POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES)).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Z-_myVCKk8ws"
   },
   "outputs": [],
   "source": [
    "def update_network(primary_network, target_network):\n",
    "    # update target network parameters slowly from primary network\n",
    "    for t, e in zip(target_network.trainable_variables, primary_network.trainable_variables):\n",
    "        t.assign(t * (1 - TAU) + e * TAU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Seq5HMPjlMvP"
   },
   "outputs": [],
   "source": [
    "def process_state_stack(state_stack, state):\n",
    "    for i in range(1, state_stack.shape[-1]):\n",
    "        state_stack[:, :, i - 1].assign(state_stack[:, :, i])\n",
    "    state_stack[:, :, -1].assign(state[:, :, 0])\n",
    "    return state_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2RY89xUilMqQ"
   },
   "outputs": [],
   "source": [
    "def record_gif(frame_list, episode, fps=50):\n",
    "    imageio.mimsave(f\"SPACE_INVADERS_EPISODE-{episode}.gif\", frame_list, fps=fps) #duration=duration_per_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUwvn4gnowA5"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dIpyeF6YlMlH"
   },
   "outputs": [],
   "source": [
    "def train(primary_network, memory, target_network=None):\n",
    "    states, actions, rewards, next_states, terminal = memory.sample()\n",
    "    # predict Q(s,a) given the batch of states\n",
    "    prim_qt = primary_network(states)\n",
    "    # predict Q(s',a') from the evaluation network\n",
    "    prim_qtp1 = primary_network(next_states)\n",
    "    # copy the prim_qt tensor into the target_q tensor - we then will update one index corresponding to the max action\n",
    "    target_q = prim_qt.numpy()\n",
    "    updates = rewards\n",
    "    valid_idxs = terminal != True\n",
    "    batch_idxs = np.arange(BATCH_SIZE)\n",
    "    if target_network is None:\n",
    "        updates[valid_idxs] += GAMMA * np.amax(prim_qtp1.numpy()[valid_idxs, :], axis=1)\n",
    "    else:\n",
    "        prim_action_tp1 = np.argmax(prim_qtp1.numpy(), axis=1)\n",
    "        q_from_target = target_network(next_states)\n",
    "        updates[valid_idxs] += GAMMA * q_from_target.numpy()[batch_idxs[valid_idxs], prim_action_tp1[valid_idxs]]\n",
    "    target_q[batch_idxs, actions] = updates\n",
    "    loss = primary_network.train_on_batch(states, target_q)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LySPiTcSi5KJ"
   },
   "outputs": [],
   "source": [
    "def prepare_tensorboard():\n",
    "    current_time = str(dt.datetime.now().strftime('%d%m%Y%H%M'))\n",
    "    log_dir = 'logs/dqn/' + current_time\n",
    "    return summary.create_file_writer(log_dir)\n",
    "\n",
    "def main():\n",
    "    num_episodes = 2000\n",
    "    eps = MAX_EPSILON\n",
    "    render = False\n",
    "    train_writer = prepare_tensorboard()\n",
    "    double_q = False\n",
    "    steps = 0\n",
    "    for i in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        state = image_preprocess(state)\n",
    "        state_stack = tf.Variable(np.repeat(state.numpy(), NUM_FRAMES).reshape((POST_PROCESS_IMAGE_SIZE[0], POST_PROCESS_IMAGE_SIZE[1], NUM_FRAMES)))\n",
    "        cnt = 1\n",
    "        avg_loss = 0\n",
    "        tot_reward = 0\n",
    "        if i % GIF_RECORDING_FREQ == 0:\n",
    "            frame_list = []\n",
    "        while True:\n",
    "            if render:\n",
    "                env.render()\n",
    "            action = choose_action(state_stack, primary_network, eps, steps)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            tot_reward += reward\n",
    "            if i % GIF_RECORDING_FREQ == 0:\n",
    "                frame_list.append(tf.cast(tf.image.resize(next_state, (480, 320)), tf.uint8).numpy())\n",
    "            next_state = image_preprocess(next_state)\n",
    "            state_stack = process_state_stack(state_stack, next_state)\n",
    "            # store in memory\n",
    "            memory.add_sample(next_state, action, reward, done)\n",
    "\n",
    "            if steps > DELAY_TRAINING:\n",
    "                loss = train(primary_network, memory, target_network if double_q else None)\n",
    "                update_network(primary_network, target_network)\n",
    "            else:\n",
    "                loss = -1\n",
    "            avg_loss += loss\n",
    "\n",
    "            # linearly decay the eps value\n",
    "            if steps > DELAY_TRAINING:\n",
    "                eps = MAX_EPSILON - ((steps - DELAY_TRAINING) / EPSILON_MIN_ITER) * \\\n",
    "                    (MAX_EPSILON - MIN_EPSILON) if steps < EPSILON_MIN_ITER else \\\n",
    "                    MIN_EPSILON\n",
    "            steps += 1\n",
    "\n",
    "            if done:\n",
    "                if steps > DELAY_TRAINING:\n",
    "                    avg_loss /= cnt\n",
    "                    print(f\"Episode: {i}, Reward: {tot_reward}, avg loss: {avg_loss:.5f}, eps: {eps:.3f}\")\n",
    "                    with train_writer.as_default():\n",
    "                        tf.summary.scalar('reward', tot_reward, step=i)\n",
    "                        tf.summary.scalar('avg loss', avg_loss, step=i)\n",
    "                else:\n",
    "                    print(f\"Pre-training...Episode: {i}\")\n",
    "                if i % GIF_RECORDING_FREQ == 0:\n",
    "                    record_gif(frame_list, i)\n",
    "                break\n",
    "\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_JpHnKRBG8C"
   },
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyOq9Q0RBJg3",
    "outputId": "31e9e726-da6e-46ee-8a92-9bc3f9fccf53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-training...Episode: 0\n",
      "Pre-training...Episode: 1\n",
      "Pre-training...Episode: 2\n",
      "Pre-training...Episode: 3\n",
      "Pre-training...Episode: 4\n",
      "Pre-training...Episode: 5\n",
      "Pre-training...Episode: 6\n",
      "Pre-training...Episode: 7\n",
      "Pre-training...Episode: 8\n",
      "Pre-training...Episode: 9\n",
      "Pre-training...Episode: 10\n",
      "Pre-training...Episode: 11\n",
      "Pre-training...Episode: 12\n",
      "Pre-training...Episode: 13\n",
      "Pre-training...Episode: 14\n",
      "Pre-training...Episode: 15\n",
      "Pre-training...Episode: 16\n",
      "Pre-training...Episode: 17\n",
      "Pre-training...Episode: 18\n",
      "Pre-training...Episode: 19\n",
      "Pre-training...Episode: 20\n",
      "Pre-training...Episode: 21\n",
      "Pre-training...Episode: 22\n",
      "Pre-training...Episode: 23\n",
      "Pre-training...Episode: 24\n",
      "Pre-training...Episode: 25\n",
      "Pre-training...Episode: 26\n",
      "Pre-training...Episode: 27\n",
      "Pre-training...Episode: 28\n",
      "Pre-training...Episode: 29\n",
      "Pre-training...Episode: 30\n",
      "Pre-training...Episode: 31\n",
      "Pre-training...Episode: 32\n",
      "Pre-training...Episode: 33\n",
      "Pre-training...Episode: 34\n",
      "Pre-training...Episode: 35\n",
      "Pre-training...Episode: 36\n",
      "Pre-training...Episode: 37\n",
      "Pre-training...Episode: 38\n",
      "Pre-training...Episode: 39\n",
      "Pre-training...Episode: 40\n",
      "Pre-training...Episode: 41\n",
      "Pre-training...Episode: 42\n",
      "Pre-training...Episode: 43\n",
      "Pre-training...Episode: 44\n",
      "Pre-training...Episode: 45\n",
      "Pre-training...Episode: 46\n",
      "Pre-training...Episode: 47\n",
      "Pre-training...Episode: 48\n",
      "Pre-training...Episode: 49\n",
      "Pre-training...Episode: 50\n",
      "Pre-training...Episode: 51\n",
      "Pre-training...Episode: 52\n",
      "Pre-training...Episode: 53\n",
      "Pre-training...Episode: 54\n",
      "Pre-training...Episode: 55\n",
      "Pre-training...Episode: 56\n",
      "Pre-training...Episode: 57\n",
      "Pre-training...Episode: 58\n",
      "Pre-training...Episode: 59\n",
      "Pre-training...Episode: 60\n",
      "Pre-training...Episode: 61\n",
      "Pre-training...Episode: 62\n",
      "Pre-training...Episode: 63\n",
      "Pre-training...Episode: 64\n",
      "Pre-training...Episode: 65\n",
      "Pre-training...Episode: 66\n",
      "Pre-training...Episode: 67\n",
      "Pre-training...Episode: 68\n",
      "Pre-training...Episode: 69\n",
      "Pre-training...Episode: 70\n",
      "Pre-training...Episode: 71\n",
      "Pre-training...Episode: 72\n",
      "Pre-training...Episode: 73\n",
      "Episode: 74, Reward: 30.0, avg loss: 0.42640, eps: 0.999\n",
      "Episode: 75, Reward: 155.0, avg loss: 0.02574, eps: 0.998\n",
      "Episode: 76, Reward: 135.0, avg loss: 0.03423, eps: 0.997\n",
      "Episode: 77, Reward: 35.0, avg loss: 0.03144, eps: 0.996\n",
      "Episode: 78, Reward: 105.0, avg loss: 0.03012, eps: 0.995\n",
      "Episode: 79, Reward: 135.0, avg loss: 0.02384, eps: 0.994\n",
      "Episode: 80, Reward: 60.0, avg loss: 0.02852, eps: 0.993\n",
      "Episode: 81, Reward: 80.0, avg loss: 0.03111, eps: 0.992\n",
      "Episode: 82, Reward: 35.0, avg loss: 0.02691, eps: 0.992\n",
      "Episode: 83, Reward: 185.0, avg loss: 159.36962, eps: 0.990\n",
      "Episode: 84, Reward: 290.0, avg loss: 0.40463, eps: 0.988\n",
      "Episode: 85, Reward: 185.0, avg loss: 0.56574, eps: 0.987\n",
      "Episode: 86, Reward: 180.0, avg loss: 0.39977, eps: 0.986\n",
      "Episode: 87, Reward: 170.0, avg loss: 1.17201, eps: 0.984\n",
      "Episode: 88, Reward: 105.0, avg loss: 0.91028, eps: 0.983\n",
      "Episode: 89, Reward: 50.0, avg loss: 1.35716, eps: 0.982\n",
      "Episode: 90, Reward: 80.0, avg loss: 1.04211, eps: 0.981\n",
      "Episode: 91, Reward: 395.0, avg loss: 0.63140, eps: 0.979\n",
      "Episode: 92, Reward: 135.0, avg loss: 0.59030, eps: 0.978\n",
      "Episode: 93, Reward: 60.0, avg loss: 0.06355, eps: 0.977\n",
      "Episode: 94, Reward: 135.0, avg loss: 0.05390, eps: 0.976\n",
      "Episode: 95, Reward: 105.0, avg loss: 0.06322, eps: 0.975\n",
      "Episode: 96, Reward: 160.0, avg loss: 0.09177, eps: 0.974\n",
      "Episode: 97, Reward: 65.0, avg loss: 0.04467, eps: 0.973\n",
      "Episode: 98, Reward: 105.0, avg loss: 0.03108, eps: 0.972\n",
      "Episode: 99, Reward: 125.0, avg loss: 0.08802, eps: 0.971\n",
      "Episode: 100, Reward: 90.0, avg loss: 0.03219, eps: 0.970\n",
      "Episode: 101, Reward: 180.0, avg loss: 0.05920, eps: 0.969\n",
      "Episode: 102, Reward: 30.0, avg loss: 0.02803, eps: 0.968\n",
      "Episode: 103, Reward: 80.0, avg loss: 0.01672, eps: 0.967\n",
      "Episode: 104, Reward: 100.0, avg loss: 0.02747, eps: 0.966\n",
      "Episode: 105, Reward: 410.0, avg loss: 0.08081, eps: 0.964\n",
      "Episode: 106, Reward: 55.0, avg loss: 12.92410, eps: 0.963\n",
      "Episode: 107, Reward: 55.0, avg loss: 0.67756, eps: 0.962\n",
      "Episode: 108, Reward: 80.0, avg loss: 0.04307, eps: 0.961\n",
      "Episode: 109, Reward: 110.0, avg loss: 0.03995, eps: 0.960\n",
      "Episode: 110, Reward: 180.0, avg loss: 0.04137, eps: 0.959\n",
      "Episode: 111, Reward: 125.0, avg loss: 0.07181, eps: 0.957\n",
      "Episode: 112, Reward: 100.0, avg loss: 0.01942, eps: 0.956\n",
      "Episode: 113, Reward: 350.0, avg loss: 0.05774, eps: 0.954\n",
      "Episode: 114, Reward: 225.0, avg loss: 0.04569, eps: 0.952\n",
      "Episode: 115, Reward: 150.0, avg loss: 0.19875, eps: 0.951\n",
      "Episode: 116, Reward: 160.0, avg loss: 0.06786, eps: 0.950\n",
      "Episode: 117, Reward: 210.0, avg loss: 0.03278, eps: 0.948\n",
      "Episode: 118, Reward: 420.0, avg loss: 0.08681, eps: 0.946\n",
      "Episode: 119, Reward: 120.0, avg loss: 0.05945, eps: 0.945\n",
      "Episode: 120, Reward: 155.0, avg loss: 0.03062, eps: 0.944\n",
      "Episode: 121, Reward: 130.0, avg loss: 0.03304, eps: 0.943\n",
      "Episode: 122, Reward: 180.0, avg loss: 0.03326, eps: 0.942\n",
      "Episode: 123, Reward: 310.0, avg loss: 0.10631, eps: 0.940\n",
      "Episode: 124, Reward: 85.0, avg loss: 0.10651, eps: 0.940\n",
      "Episode: 125, Reward: 95.0, avg loss: 0.03367, eps: 0.938\n",
      "Episode: 126, Reward: 120.0, avg loss: 0.02387, eps: 0.937\n",
      "Episode: 127, Reward: 130.0, avg loss: 0.02167, eps: 0.936\n",
      "Episode: 128, Reward: 240.0, avg loss: 0.03252, eps: 0.934\n",
      "Episode: 129, Reward: 110.0, avg loss: 0.03689, eps: 0.933\n",
      "Episode: 130, Reward: 135.0, avg loss: 0.01465, eps: 0.932\n",
      "Episode: 131, Reward: 575.0, avg loss: 1.78046, eps: 0.930\n",
      "Episode: 132, Reward: 155.0, avg loss: 0.09347, eps: 0.928\n",
      "Episode: 133, Reward: 170.0, avg loss: 0.04177, eps: 0.927\n",
      "Episode: 134, Reward: 315.0, avg loss: 0.05017, eps: 0.925\n",
      "Episode: 135, Reward: 225.0, avg loss: 0.05893, eps: 0.924\n",
      "Episode: 136, Reward: 105.0, avg loss: 0.06537, eps: 0.923\n",
      "Episode: 137, Reward: 110.0, avg loss: 0.03424, eps: 0.922\n",
      "Episode: 138, Reward: 265.0, avg loss: 0.02517, eps: 0.920\n",
      "Episode: 139, Reward: 105.0, avg loss: 0.00767, eps: 0.919\n",
      "Episode: 140, Reward: 75.0, avg loss: 0.02454, eps: 0.918\n",
      "Episode: 141, Reward: 70.0, avg loss: 0.04776, eps: 0.917\n",
      "Episode: 142, Reward: 115.0, avg loss: 0.03464, eps: 0.916\n",
      "Episode: 143, Reward: 185.0, avg loss: 0.04003, eps: 0.914\n",
      "Episode: 144, Reward: 180.0, avg loss: 0.04974, eps: 0.913\n",
      "Episode: 145, Reward: 110.0, avg loss: 0.04866, eps: 0.911\n",
      "Episode: 146, Reward: 20.0, avg loss: 0.00874, eps: 0.911\n",
      "Episode: 147, Reward: 60.0, avg loss: 0.00998, eps: 0.910\n",
      "Episode: 148, Reward: 105.0, avg loss: 0.03112, eps: 0.909\n",
      "Episode: 149, Reward: 90.0, avg loss: 0.03270, eps: 0.908\n",
      "Episode: 150, Reward: 60.0, avg loss: 0.04346, eps: 0.907\n",
      "Episode: 151, Reward: 180.0, avg loss: 0.03316, eps: 0.906\n",
      "Episode: 152, Reward: 105.0, avg loss: 0.03677, eps: 0.904\n",
      "Episode: 153, Reward: 55.0, avg loss: 0.01776, eps: 0.903\n",
      "Episode: 154, Reward: 310.0, avg loss: 0.46176, eps: 0.902\n",
      "Episode: 155, Reward: 210.0, avg loss: 0.17886, eps: 0.900\n",
      "Episode: 156, Reward: 270.0, avg loss: 0.12052, eps: 0.898\n",
      "Episode: 157, Reward: 135.0, avg loss: 0.07879, eps: 0.897\n",
      "Episode: 158, Reward: 135.0, avg loss: 0.07955, eps: 0.896\n",
      "Episode: 159, Reward: 135.0, avg loss: 0.05991, eps: 0.895\n",
      "Episode: 160, Reward: 135.0, avg loss: 0.04244, eps: 0.894\n",
      "Episode: 161, Reward: 185.0, avg loss: 0.05631, eps: 0.892\n",
      "Episode: 162, Reward: 105.0, avg loss: 0.03878, eps: 0.891\n",
      "Episode: 163, Reward: 95.0, avg loss: 0.73790, eps: 0.890\n",
      "Episode: 164, Reward: 110.0, avg loss: 0.10393, eps: 0.889\n",
      "Episode: 165, Reward: 410.0, avg loss: 0.12734, eps: 0.888\n",
      "Episode: 166, Reward: 120.0, avg loss: 0.09889, eps: 0.887\n",
      "Episode: 167, Reward: 75.0, avg loss: 0.05124, eps: 0.886\n",
      "Episode: 168, Reward: 120.0, avg loss: 0.04486, eps: 0.884\n",
      "Episode: 169, Reward: 350.0, avg loss: 0.07586, eps: 0.883\n",
      "Episode: 170, Reward: 155.0, avg loss: 0.12851, eps: 0.882\n",
      "Episode: 171, Reward: 125.0, avg loss: 0.06007, eps: 0.880\n",
      "Episode: 172, Reward: 115.0, avg loss: 0.06738, eps: 0.880\n",
      "Episode: 173, Reward: 465.0, avg loss: 0.34197, eps: 0.878\n",
      "Episode: 174, Reward: 80.0, avg loss: 0.12387, eps: 0.877\n",
      "Episode: 175, Reward: 120.0, avg loss: 0.52367, eps: 0.876\n",
      "Episode: 176, Reward: 155.0, avg loss: 0.19342, eps: 0.875\n",
      "Episode: 177, Reward: 180.0, avg loss: 0.24845, eps: 0.874\n",
      "Episode: 178, Reward: 210.0, avg loss: 0.20941, eps: 0.872\n",
      "Episode: 179, Reward: 210.0, avg loss: 0.13408, eps: 0.871\n",
      "Episode: 180, Reward: 180.0, avg loss: 0.09508, eps: 0.870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 181, Reward: 215.0, avg loss: 0.10937, eps: 0.868\n",
      "Episode: 182, Reward: 150.0, avg loss: 0.10022, eps: 0.867\n",
      "Episode: 183, Reward: 225.0, avg loss: 0.06534, eps: 0.865\n",
      "Episode: 184, Reward: 185.0, avg loss: 0.16843, eps: 0.863\n",
      "Episode: 185, Reward: 125.0, avg loss: 0.24088, eps: 0.862\n",
      "Episode: 186, Reward: 210.0, avg loss: 0.10590, eps: 0.861\n",
      "Episode: 187, Reward: 170.0, avg loss: 0.06437, eps: 0.859\n",
      "Episode: 188, Reward: 105.0, avg loss: 0.04068, eps: 0.859\n",
      "Episode: 189, Reward: 85.0, avg loss: 0.04222, eps: 0.857\n",
      "Episode: 190, Reward: 515.0, avg loss: 0.06016, eps: 0.855\n",
      "Episode: 191, Reward: 135.0, avg loss: 0.08685, eps: 0.854\n",
      "Episode: 192, Reward: 105.0, avg loss: 0.05043, eps: 0.853\n",
      "Episode: 193, Reward: 115.0, avg loss: 0.04939, eps: 0.852\n",
      "Episode: 194, Reward: 80.0, avg loss: 0.04887, eps: 0.851\n",
      "Episode: 195, Reward: 110.0, avg loss: 0.17549, eps: 0.850\n",
      "Episode: 196, Reward: 45.0, avg loss: 0.08904, eps: 0.849\n",
      "Episode: 197, Reward: 105.0, avg loss: 0.07062, eps: 0.848\n",
      "Episode: 198, Reward: 135.0, avg loss: 0.07340, eps: 0.847\n",
      "Episode: 199, Reward: 180.0, avg loss: 0.04605, eps: 0.845\n",
      "Episode: 200, Reward: 50.0, avg loss: 0.04401, eps: 0.845\n",
      "Episode: 201, Reward: 180.0, avg loss: 0.04533, eps: 0.844\n",
      "Episode: 202, Reward: 160.0, avg loss: 0.02139, eps: 0.842\n",
      "Episode: 203, Reward: 120.0, avg loss: 0.03037, eps: 0.841\n",
      "Episode: 204, Reward: 235.0, avg loss: 0.03067, eps: 0.839\n",
      "Episode: 205, Reward: 35.0, avg loss: 0.11203, eps: 0.838\n",
      "Episode: 206, Reward: 215.0, avg loss: 0.04753, eps: 0.836\n",
      "Episode: 207, Reward: 80.0, avg loss: 0.09681, eps: 0.835\n",
      "Episode: 208, Reward: 125.0, avg loss: 0.05254, eps: 0.834\n",
      "Episode: 209, Reward: 190.0, avg loss: 0.07061, eps: 0.832\n",
      "Episode: 210, Reward: 120.0, avg loss: 0.13127, eps: 0.831\n",
      "Episode: 211, Reward: 110.0, avg loss: 0.06773, eps: 0.830\n",
      "Episode: 212, Reward: 135.0, avg loss: 1.27818, eps: 0.829\n",
      "Episode: 213, Reward: 110.0, avg loss: 0.23954, eps: 0.827\n",
      "Episode: 214, Reward: 105.0, avg loss: 0.07865, eps: 0.826\n",
      "Episode: 215, Reward: 20.0, avg loss: 0.07860, eps: 0.825\n",
      "Episode: 216, Reward: 50.0, avg loss: 0.04153, eps: 0.824\n",
      "Episode: 217, Reward: 105.0, avg loss: 0.13432, eps: 0.824\n",
      "Episode: 218, Reward: 175.0, avg loss: 0.07087, eps: 0.822\n",
      "Episode: 219, Reward: 110.0, avg loss: 0.05089, eps: 0.821\n",
      "Episode: 220, Reward: 510.0, avg loss: 0.09888, eps: 0.819\n",
      "Episode: 221, Reward: 70.0, avg loss: 0.04267, eps: 0.818\n",
      "Episode: 222, Reward: 105.0, avg loss: 0.02937, eps: 0.818\n",
      "Episode: 223, Reward: 175.0, avg loss: 0.05436, eps: 0.816\n",
      "Episode: 224, Reward: 20.0, avg loss: 0.02843, eps: 0.816\n",
      "Episode: 225, Reward: 80.0, avg loss: 0.16813, eps: 0.815\n",
      "Episode: 226, Reward: 135.0, avg loss: 0.05730, eps: 0.813\n",
      "Episode: 227, Reward: 80.0, avg loss: 0.05034, eps: 0.813\n",
      "Episode: 228, Reward: 65.0, avg loss: 0.07270, eps: 0.812\n",
      "Episode: 229, Reward: 90.0, avg loss: 0.03361, eps: 0.810\n",
      "Episode: 230, Reward: 165.0, avg loss: 0.12973, eps: 0.809\n",
      "Episode: 231, Reward: 290.0, avg loss: 0.08565, eps: 0.807\n",
      "Episode: 232, Reward: 50.0, avg loss: 0.07509, eps: 0.806\n",
      "Episode: 233, Reward: 105.0, avg loss: 0.06119, eps: 0.805\n",
      "Episode: 234, Reward: 130.0, avg loss: 0.04766, eps: 0.804\n",
      "Episode: 235, Reward: 155.0, avg loss: 0.06249, eps: 0.803\n",
      "Episode: 236, Reward: 200.0, avg loss: 0.04308, eps: 0.802\n",
      "Episode: 237, Reward: 125.0, avg loss: 0.03835, eps: 0.800\n",
      "Episode: 238, Reward: 225.0, avg loss: 0.04646, eps: 0.798\n",
      "Episode: 239, Reward: 120.0, avg loss: 0.33974, eps: 0.797\n",
      "Episode: 240, Reward: 30.0, avg loss: 0.03026, eps: 0.796\n",
      "Episode: 241, Reward: 120.0, avg loss: 0.02450, eps: 0.795\n",
      "Episode: 242, Reward: 115.0, avg loss: 0.05395, eps: 0.794\n",
      "Episode: 243, Reward: 65.0, avg loss: 0.03891, eps: 0.793\n",
      "Episode: 244, Reward: 65.0, avg loss: 0.05605, eps: 0.793\n",
      "Episode: 245, Reward: 170.0, avg loss: 0.02633, eps: 0.791\n",
      "Episode: 246, Reward: 20.0, avg loss: 0.04308, eps: 0.791\n",
      "Episode: 247, Reward: 405.0, avg loss: 0.20894, eps: 0.788\n",
      "Episode: 248, Reward: 410.0, avg loss: 0.13163, eps: 0.787\n",
      "Episode: 249, Reward: 620.0, avg loss: 0.14284, eps: 0.785\n",
      "Episode: 250, Reward: 260.0, avg loss: 0.05876, eps: 0.783\n",
      "Episode: 251, Reward: 210.0, avg loss: 0.03304, eps: 0.782\n",
      "Episode: 252, Reward: 160.0, avg loss: 0.03697, eps: 0.780\n",
      "Episode: 253, Reward: 195.0, avg loss: 0.02676, eps: 0.779\n",
      "Episode: 254, Reward: 135.0, avg loss: 0.02726, eps: 0.777\n",
      "Episode: 255, Reward: 20.0, avg loss: 0.02791, eps: 0.776\n",
      "Episode: 256, Reward: 80.0, avg loss: 0.04138, eps: 0.775\n",
      "Episode: 257, Reward: 135.0, avg loss: 0.22722, eps: 0.774\n",
      "Episode: 258, Reward: 185.0, avg loss: 0.05044, eps: 0.773\n",
      "Episode: 259, Reward: 410.0, avg loss: 0.07268, eps: 0.771\n",
      "Episode: 260, Reward: 120.0, avg loss: 0.02866, eps: 0.770\n",
      "Episode: 261, Reward: 215.0, avg loss: 0.05372, eps: 0.768\n",
      "Episode: 262, Reward: 105.0, avg loss: 0.03587, eps: 0.767\n",
      "Episode: 263, Reward: 105.0, avg loss: 0.01839, eps: 0.766\n",
      "Episode: 264, Reward: 55.0, avg loss: 0.02255, eps: 0.766\n",
      "Episode: 265, Reward: 185.0, avg loss: 0.03023, eps: 0.764\n",
      "Episode: 266, Reward: 145.0, avg loss: 0.02981, eps: 0.763\n",
      "Episode: 267, Reward: 210.0, avg loss: 0.41923, eps: 0.761\n",
      "Episode: 268, Reward: 80.0, avg loss: 0.53397, eps: 0.760\n",
      "Episode: 269, Reward: 100.0, avg loss: 0.20759, eps: 0.759\n",
      "Episode: 270, Reward: 125.0, avg loss: 0.18069, eps: 0.758\n",
      "Episode: 271, Reward: 155.0, avg loss: 0.16863, eps: 0.757\n",
      "Episode: 272, Reward: 105.0, avg loss: 0.63215, eps: 0.755\n",
      "Episode: 273, Reward: 125.0, avg loss: 0.12579, eps: 0.754\n",
      "Episode: 274, Reward: 175.0, avg loss: 0.12829, eps: 0.753\n",
      "Episode: 275, Reward: 90.0, avg loss: 0.12785, eps: 0.752\n",
      "Episode: 276, Reward: 135.0, avg loss: 0.60235, eps: 0.751\n",
      "Episode: 277, Reward: 60.0, avg loss: 0.17165, eps: 0.749\n",
      "Episode: 278, Reward: 20.0, avg loss: 0.16191, eps: 0.749\n",
      "Episode: 279, Reward: 510.0, avg loss: 0.17000, eps: 0.747\n",
      "Episode: 280, Reward: 210.0, avg loss: 0.11986, eps: 0.746\n",
      "Episode: 281, Reward: 135.0, avg loss: 0.79960, eps: 0.744\n",
      "Episode: 282, Reward: 440.0, avg loss: 0.40885, eps: 0.742\n",
      "Episode: 283, Reward: 260.0, avg loss: 0.10642, eps: 0.740\n",
      "Episode: 284, Reward: 45.0, avg loss: 0.05307, eps: 0.739\n",
      "Episode: 285, Reward: 20.0, avg loss: 0.04771, eps: 0.739\n",
      "Episode: 286, Reward: 135.0, avg loss: 0.04835, eps: 0.738\n",
      "Episode: 287, Reward: 30.0, avg loss: 0.03813, eps: 0.737\n",
      "Episode: 288, Reward: 415.0, avg loss: 0.29711, eps: 0.735\n",
      "Episode: 289, Reward: 150.0, avg loss: 0.15367, eps: 0.734\n",
      "Episode: 290, Reward: 105.0, avg loss: 0.10739, eps: 0.733\n",
      "Episode: 291, Reward: 30.0, avg loss: 0.02937, eps: 0.732\n",
      "Episode: 292, Reward: 410.0, avg loss: 0.14179, eps: 0.730\n",
      "Episode: 293, Reward: 210.0, avg loss: 0.30531, eps: 0.729\n",
      "Episode: 294, Reward: 90.0, avg loss: 0.38278, eps: 0.728\n",
      "Episode: 295, Reward: 80.0, avg loss: 0.24266, eps: 0.727\n",
      "Episode: 296, Reward: 105.0, avg loss: 0.13132, eps: 0.726\n",
      "Episode: 297, Reward: 365.0, avg loss: 0.13435, eps: 0.724\n",
      "Episode: 298, Reward: 130.0, avg loss: 0.55950, eps: 0.723\n",
      "Episode: 299, Reward: 85.0, avg loss: 0.25781, eps: 0.722\n",
      "Episode: 300, Reward: 120.0, avg loss: 0.12009, eps: 0.721\n",
      "Episode: 301, Reward: 65.0, avg loss: 0.13018, eps: 0.720\n",
      "Episode: 302, Reward: 280.0, avg loss: 0.52249, eps: 0.718\n",
      "Episode: 303, Reward: 155.0, avg loss: 0.81208, eps: 0.717\n",
      "Episode: 304, Reward: 165.0, avg loss: 0.38240, eps: 0.716\n",
      "Episode: 305, Reward: 70.0, avg loss: 0.08159, eps: 0.715\n",
      "Episode: 306, Reward: 125.0, avg loss: 0.04138, eps: 0.714\n",
      "Episode: 307, Reward: 120.0, avg loss: 0.26282, eps: 0.712\n",
      "Episode: 308, Reward: 55.0, avg loss: 0.70002, eps: 0.712\n",
      "Episode: 309, Reward: 90.0, avg loss: 0.33579, eps: 0.711\n",
      "Episode: 310, Reward: 230.0, avg loss: 0.56462, eps: 0.709\n",
      "Episode: 311, Reward: 330.0, avg loss: 0.63501, eps: 0.707\n",
      "Episode: 312, Reward: 125.0, avg loss: 0.25596, eps: 0.706\n",
      "Episode: 313, Reward: 60.0, avg loss: 0.37295, eps: 0.705\n",
      "Episode: 314, Reward: 195.0, avg loss: 0.23208, eps: 0.703\n",
      "Episode: 315, Reward: 415.0, avg loss: 0.18274, eps: 0.702\n",
      "Episode: 316, Reward: 5.0, avg loss: 0.37104, eps: 0.701\n",
      "Episode: 317, Reward: 130.0, avg loss: 0.21518, eps: 0.700\n",
      "Episode: 318, Reward: 30.0, avg loss: 10.93867, eps: 0.699\n",
      "Episode: 319, Reward: 455.0, avg loss: 0.76882, eps: 0.697\n",
      "Episode: 320, Reward: 50.0, avg loss: 0.27659, eps: 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 321, Reward: 85.0, avg loss: 0.22279, eps: 0.694\n",
      "Episode: 322, Reward: 80.0, avg loss: 0.04945, eps: 0.693\n",
      "Episode: 323, Reward: 110.0, avg loss: 0.04451, eps: 0.692\n",
      "Episode: 324, Reward: 30.0, avg loss: 0.03332, eps: 0.692\n",
      "Episode: 325, Reward: 135.0, avg loss: 0.02876, eps: 0.691\n",
      "Episode: 326, Reward: 135.0, avg loss: 0.03133, eps: 0.689\n",
      "Episode: 327, Reward: 10.0, avg loss: 0.01915, eps: 0.689\n",
      "Episode: 328, Reward: 355.0, avg loss: 0.01712, eps: 0.687\n",
      "Episode: 329, Reward: 30.0, avg loss: 0.01792, eps: 0.687\n",
      "Episode: 330, Reward: 80.0, avg loss: 0.01026, eps: 0.685\n",
      "Episode: 331, Reward: 110.0, avg loss: 0.01485, eps: 0.685\n",
      "Episode: 332, Reward: 105.0, avg loss: 0.02066, eps: 0.683\n",
      "Episode: 333, Reward: 110.0, avg loss: 0.02104, eps: 0.682\n",
      "Episode: 334, Reward: 345.0, avg loss: 0.47315, eps: 0.680\n",
      "Episode: 335, Reward: 335.0, avg loss: 0.87233, eps: 0.679\n",
      "Episode: 336, Reward: 305.0, avg loss: 0.11363, eps: 0.677\n",
      "Episode: 337, Reward: 330.0, avg loss: 0.04942, eps: 0.675\n",
      "Episode: 338, Reward: 190.0, avg loss: 0.03553, eps: 0.673\n",
      "Episode: 339, Reward: 260.0, avg loss: 0.03119, eps: 0.671\n",
      "Episode: 340, Reward: 210.0, avg loss: 0.03605, eps: 0.670\n",
      "Episode: 341, Reward: 110.0, avg loss: 0.02976, eps: 0.669\n",
      "Episode: 342, Reward: 155.0, avg loss: 0.03255, eps: 0.667\n",
      "Episode: 343, Reward: 135.0, avg loss: 0.01480, eps: 0.666\n",
      "Episode: 344, Reward: 120.0, avg loss: 0.02094, eps: 0.665\n",
      "Episode: 345, Reward: 30.0, avg loss: 0.00950, eps: 0.664\n",
      "Episode: 346, Reward: 130.0, avg loss: 0.01212, eps: 0.663\n",
      "Episode: 347, Reward: 245.0, avg loss: 0.07396, eps: 0.661\n",
      "Episode: 348, Reward: 215.0, avg loss: 0.68998, eps: 0.659\n",
      "Episode: 349, Reward: 110.0, avg loss: 0.25799, eps: 0.658\n",
      "Episode: 350, Reward: 415.0, avg loss: 0.17570, eps: 0.656\n",
      "Episode: 351, Reward: 145.0, avg loss: 0.39595, eps: 0.655\n",
      "Episode: 352, Reward: 210.0, avg loss: 1.09254, eps: 0.654\n",
      "Episode: 353, Reward: 140.0, avg loss: 0.53237, eps: 0.653\n",
      "Episode: 354, Reward: 380.0, avg loss: 0.35393, eps: 0.651\n",
      "Episode: 355, Reward: 35.0, avg loss: 0.37682, eps: 0.650\n",
      "Episode: 356, Reward: 60.0, avg loss: 0.16052, eps: 0.649\n",
      "Episode: 357, Reward: 410.0, avg loss: 0.18188, eps: 0.647\n",
      "Episode: 358, Reward: 105.0, avg loss: 0.21550, eps: 0.646\n",
      "Episode: 359, Reward: 730.0, avg loss: 0.23532, eps: 0.643\n",
      "Episode: 360, Reward: 95.0, avg loss: 0.31178, eps: 0.642\n",
      "Episode: 361, Reward: 240.0, avg loss: 0.18545, eps: 0.641\n",
      "Episode: 362, Reward: 125.0, avg loss: 0.15284, eps: 0.640\n",
      "Episode: 363, Reward: 125.0, avg loss: 0.85102, eps: 0.638\n",
      "Episode: 364, Reward: 410.0, avg loss: 0.21588, eps: 0.636\n",
      "Episode: 365, Reward: 320.0, avg loss: 0.31609, eps: 0.634\n",
      "Episode: 366, Reward: 70.0, avg loss: 0.17915, eps: 0.633\n",
      "Episode: 367, Reward: 105.0, avg loss: 0.16824, eps: 0.632\n",
      "Episode: 368, Reward: 35.0, avg loss: 3.37321, eps: 0.631\n",
      "Episode: 369, Reward: 45.0, avg loss: 0.74961, eps: 0.630\n",
      "Episode: 370, Reward: 60.0, avg loss: 0.03420, eps: 0.630\n",
      "Episode: 371, Reward: 260.0, avg loss: 0.16344, eps: 0.628\n",
      "Episode: 372, Reward: 65.0, avg loss: 0.16421, eps: 0.627\n",
      "Episode: 373, Reward: 70.0, avg loss: 0.05279, eps: 0.626\n",
      "Episode: 374, Reward: 35.0, avg loss: 0.07958, eps: 0.625\n",
      "Episode: 375, Reward: 170.0, avg loss: 0.19407, eps: 0.624\n",
      "Episode: 376, Reward: 225.0, avg loss: 0.32808, eps: 0.622\n",
      "Episode: 377, Reward: 175.0, avg loss: 0.34219, eps: 0.621\n",
      "Episode: 378, Reward: 60.0, avg loss: 0.28618, eps: 0.620\n",
      "Episode: 379, Reward: 150.0, avg loss: 0.24652, eps: 0.618\n",
      "Episode: 380, Reward: 105.0, avg loss: 0.11525, eps: 0.618\n",
      "Episode: 381, Reward: 135.0, avg loss: 0.09123, eps: 0.616\n",
      "Episode: 382, Reward: 135.0, avg loss: 0.90596, eps: 0.615\n",
      "Episode: 383, Reward: 210.0, avg loss: 0.19508, eps: 0.614\n",
      "Episode: 384, Reward: 420.0, avg loss: 0.47835, eps: 0.612\n",
      "Episode: 385, Reward: 640.0, avg loss: 0.23679, eps: 0.610\n",
      "Episode: 386, Reward: 35.0, avg loss: 0.32026, eps: 0.609\n",
      "Episode: 387, Reward: 260.0, avg loss: 0.17001, eps: 0.607\n",
      "Episode: 388, Reward: 210.0, avg loss: 0.11175, eps: 0.605\n",
      "Episode: 389, Reward: 130.0, avg loss: 0.23368, eps: 0.604\n",
      "Episode: 390, Reward: 170.0, avg loss: 0.35445, eps: 0.602\n",
      "Episode: 391, Reward: 285.0, avg loss: 0.93861, eps: 0.600\n",
      "Episode: 392, Reward: 90.0, avg loss: 0.43573, eps: 0.599\n",
      "Episode: 393, Reward: 345.0, avg loss: 0.66019, eps: 0.597\n",
      "Episode: 394, Reward: 75.0, avg loss: 0.45214, eps: 0.596\n",
      "Episode: 395, Reward: 85.0, avg loss: 0.07324, eps: 0.595\n",
      "Episode: 396, Reward: 145.0, avg loss: 0.61381, eps: 0.593\n",
      "Episode: 397, Reward: 365.0, avg loss: 1.14350, eps: 0.591\n",
      "Episode: 398, Reward: 65.0, avg loss: 0.93322, eps: 0.591\n",
      "Episode: 399, Reward: 110.0, avg loss: 0.38247, eps: 0.590\n",
      "Episode: 400, Reward: 390.0, avg loss: 0.67279, eps: 0.588\n",
      "Episode: 401, Reward: 85.0, avg loss: 0.58646, eps: 0.587\n",
      "Episode: 402, Reward: 190.0, avg loss: 0.43958, eps: 0.585\n",
      "Episode: 403, Reward: 210.0, avg loss: 0.65872, eps: 0.584\n",
      "Episode: 404, Reward: 40.0, avg loss: 0.26342, eps: 0.583\n",
      "Episode: 405, Reward: 110.0, avg loss: 0.26340, eps: 0.582\n",
      "Episode: 406, Reward: 50.0, avg loss: 0.28104, eps: 0.581\n",
      "Episode: 407, Reward: 105.0, avg loss: 0.26875, eps: 0.579\n",
      "Episode: 408, Reward: 130.0, avg loss: 0.64130, eps: 0.578\n",
      "Episode: 409, Reward: 20.0, avg loss: 1.13496, eps: 0.578\n",
      "Episode: 410, Reward: 155.0, avg loss: 0.82991, eps: 0.576\n",
      "Episode: 411, Reward: 175.0, avg loss: 0.59609, eps: 0.575\n",
      "Episode: 412, Reward: 410.0, avg loss: 0.81028, eps: 0.573\n",
      "Episode: 413, Reward: 350.0, avg loss: 1.37347, eps: 0.571\n",
      "Episode: 414, Reward: 210.0, avg loss: 0.82888, eps: 0.569\n",
      "Episode: 415, Reward: 125.0, avg loss: 0.78282, eps: 0.568\n",
      "Episode: 416, Reward: 120.0, avg loss: 0.54005, eps: 0.567\n",
      "Episode: 417, Reward: 105.0, avg loss: 0.48231, eps: 0.565\n",
      "Episode: 418, Reward: 50.0, avg loss: 0.21818, eps: 0.564\n",
      "Episode: 419, Reward: 240.0, avg loss: 0.22441, eps: 0.563\n",
      "Episode: 420, Reward: 170.0, avg loss: 0.41545, eps: 0.561\n",
      "Episode: 421, Reward: 145.0, avg loss: 0.23723, eps: 0.559\n",
      "Episode: 422, Reward: 30.0, avg loss: 0.07993, eps: 0.559\n",
      "Episode: 423, Reward: 55.0, avg loss: 0.08246, eps: 0.558\n",
      "Episode: 424, Reward: 185.0, avg loss: 0.24054, eps: 0.556\n",
      "Episode: 425, Reward: 225.0, avg loss: 1.02293, eps: 0.554\n",
      "Episode: 426, Reward: 130.0, avg loss: 0.94943, eps: 0.553\n",
      "Episode: 427, Reward: 180.0, avg loss: 1.94912, eps: 0.552\n",
      "Episode: 428, Reward: 170.0, avg loss: 1.17551, eps: 0.551\n",
      "Episode: 429, Reward: 135.0, avg loss: 0.71280, eps: 0.550\n",
      "Episode: 430, Reward: 60.0, avg loss: 0.40774, eps: 0.548\n",
      "Episode: 431, Reward: 235.0, avg loss: 1.81051, eps: 0.547\n",
      "Episode: 432, Reward: 270.0, avg loss: 1.68806, eps: 0.545\n",
      "Episode: 433, Reward: 70.0, avg loss: 1.50773, eps: 0.544\n",
      "Episode: 434, Reward: 285.0, avg loss: 1.50456, eps: 0.542\n",
      "Episode: 435, Reward: 485.0, avg loss: 1.58775, eps: 0.540\n",
      "Episode: 436, Reward: 20.0, avg loss: 1.03102, eps: 0.539\n",
      "Episode: 437, Reward: 460.0, avg loss: 0.86502, eps: 0.537\n",
      "Episode: 438, Reward: 130.0, avg loss: 0.59231, eps: 0.536\n",
      "Episode: 439, Reward: 265.0, avg loss: 0.99877, eps: 0.534\n",
      "Episode: 440, Reward: 110.0, avg loss: 1.41966, eps: 0.532\n",
      "Episode: 441, Reward: 75.0, avg loss: 0.61634, eps: 0.531\n",
      "Episode: 442, Reward: 200.0, avg loss: 0.59143, eps: 0.530\n",
      "Episode: 443, Reward: 140.0, avg loss: 0.47396, eps: 0.529\n",
      "Episode: 444, Reward: 195.0, avg loss: 0.32312, eps: 0.527\n",
      "Episode: 445, Reward: 240.0, avg loss: 0.44048, eps: 0.526\n",
      "Episode: 446, Reward: 190.0, avg loss: 0.20682, eps: 0.525\n",
      "Episode: 447, Reward: 90.0, avg loss: 0.21256, eps: 0.524\n",
      "Episode: 448, Reward: 95.0, avg loss: 0.84165, eps: 0.523\n",
      "Episode: 449, Reward: 195.0, avg loss: 2.20828, eps: 0.522\n",
      "Episode: 450, Reward: 90.0, avg loss: 1.69328, eps: 0.520\n",
      "Episode: 451, Reward: 260.0, avg loss: 1.20162, eps: 0.519\n",
      "Episode: 452, Reward: 140.0, avg loss: 1.20406, eps: 0.517\n",
      "Episode: 453, Reward: 60.0, avg loss: 0.46310, eps: 0.517\n",
      "Episode: 454, Reward: 285.0, avg loss: 0.56531, eps: 0.515\n",
      "Episode: 455, Reward: 205.0, avg loss: 0.27637, eps: 0.514\n",
      "Episode: 456, Reward: 65.0, avg loss: 0.85545, eps: 0.512\n",
      "Episode: 457, Reward: 115.0, avg loss: 1.88859, eps: 0.511\n",
      "Episode: 458, Reward: 30.0, avg loss: 1.98644, eps: 0.511\n",
      "Episode: 459, Reward: 35.0, avg loss: 0.77980, eps: 0.510\n",
      "Episode: 460, Reward: 410.0, avg loss: 1.70765, eps: 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 461, Reward: 120.0, avg loss: 3.25836, eps: 0.507\n",
      "Episode: 462, Reward: 65.0, avg loss: 1.13623, eps: 0.506\n",
      "Episode: 463, Reward: 60.0, avg loss: 0.56421, eps: 0.505\n",
      "Episode: 464, Reward: 615.0, avg loss: 1.77847, eps: 0.503\n",
      "Episode: 465, Reward: 50.0, avg loss: 2.34744, eps: 0.502\n",
      "Episode: 466, Reward: 135.0, avg loss: 1.58656, eps: 0.501\n",
      "Episode: 467, Reward: 85.0, avg loss: 1.91406, eps: 0.501\n",
      "Episode: 468, Reward: 110.0, avg loss: 0.56708, eps: 0.500\n",
      "Episode: 469, Reward: 190.0, avg loss: 0.59049, eps: 0.498\n",
      "Episode: 470, Reward: 270.0, avg loss: 0.54459, eps: 0.496\n",
      "Episode: 471, Reward: 155.0, avg loss: 1.44113, eps: 0.495\n",
      "Episode: 472, Reward: 180.0, avg loss: 0.51643, eps: 0.494\n",
      "Episode: 473, Reward: 415.0, avg loss: 1.50916, eps: 0.492\n",
      "Episode: 474, Reward: 155.0, avg loss: 1.68308, eps: 0.491\n",
      "Episode: 475, Reward: 155.0, avg loss: 0.90256, eps: 0.489\n",
      "Episode: 476, Reward: 250.0, avg loss: 0.60321, eps: 0.488\n",
      "Episode: 477, Reward: 485.0, avg loss: 1.06721, eps: 0.486\n",
      "Episode: 478, Reward: 145.0, avg loss: 1.13099, eps: 0.484\n",
      "Episode: 479, Reward: 180.0, avg loss: 1.89722, eps: 0.483\n",
      "Episode: 480, Reward: 125.0, avg loss: 1.88531, eps: 0.482\n",
      "Episode: 481, Reward: 35.0, avg loss: 0.61399, eps: 0.481\n",
      "Episode: 482, Reward: 215.0, avg loss: 0.52665, eps: 0.479\n",
      "Episode: 483, Reward: 105.0, avg loss: 1.27417, eps: 0.478\n",
      "Episode: 484, Reward: 120.0, avg loss: 0.54855, eps: 0.477\n",
      "Episode: 485, Reward: 70.0, avg loss: 0.19483, eps: 0.476\n",
      "Episode: 486, Reward: 255.0, avg loss: 0.40659, eps: 0.474\n",
      "Episode: 487, Reward: 420.0, avg loss: 0.58625, eps: 0.472\n",
      "Episode: 488, Reward: 30.0, avg loss: 0.85957, eps: 0.471\n",
      "Episode: 489, Reward: 40.0, avg loss: 0.49942, eps: 0.470\n",
      "Episode: 490, Reward: 140.0, avg loss: 0.88010, eps: 0.469\n",
      "Episode: 491, Reward: 225.0, avg loss: 1.32650, eps: 0.468\n",
      "Episode: 492, Reward: 200.0, avg loss: 0.07905, eps: 0.467\n",
      "Episode: 493, Reward: 25.0, avg loss: 0.17277, eps: 0.466\n",
      "Episode: 494, Reward: 210.0, avg loss: 0.05763, eps: 0.464\n",
      "Episode: 495, Reward: 135.0, avg loss: 0.65305, eps: 0.463\n",
      "Episode: 496, Reward: 55.0, avg loss: 0.39844, eps: 0.463\n",
      "Episode: 497, Reward: 110.0, avg loss: 0.56578, eps: 0.462\n",
      "Episode: 498, Reward: 295.0, avg loss: 1.02204, eps: 0.460\n",
      "Episode: 499, Reward: 85.0, avg loss: 1.03572, eps: 0.459\n",
      "Episode: 500, Reward: 125.0, avg loss: 1.19317, eps: 0.457\n",
      "Episode: 501, Reward: 165.0, avg loss: 0.59693, eps: 0.456\n",
      "Episode: 502, Reward: 315.0, avg loss: 1.50371, eps: 0.454\n",
      "Episode: 503, Reward: 210.0, avg loss: 1.11424, eps: 0.453\n",
      "Episode: 504, Reward: 60.0, avg loss: 0.48685, eps: 0.452\n",
      "Episode: 505, Reward: 125.0, avg loss: 0.24106, eps: 0.451\n",
      "Episode: 506, Reward: 225.0, avg loss: 1.06783, eps: 0.449\n",
      "Episode: 507, Reward: 215.0, avg loss: 1.50238, eps: 0.448\n",
      "Episode: 508, Reward: 190.0, avg loss: 0.32502, eps: 0.446\n",
      "Episode: 509, Reward: 75.0, avg loss: 0.36110, eps: 0.446\n",
      "Episode: 510, Reward: 250.0, avg loss: 0.28106, eps: 0.444\n",
      "Episode: 511, Reward: 400.0, avg loss: 0.12689, eps: 0.442\n",
      "Episode: 512, Reward: 240.0, avg loss: 0.06870, eps: 0.441\n",
      "Episode: 513, Reward: 125.0, avg loss: 0.05570, eps: 0.440\n",
      "Episode: 514, Reward: 155.0, avg loss: 0.04331, eps: 0.438\n",
      "Episode: 515, Reward: 230.0, avg loss: 0.04459, eps: 0.437\n",
      "Episode: 516, Reward: 120.0, avg loss: 0.04403, eps: 0.436\n",
      "Episode: 517, Reward: 235.0, avg loss: 0.02285, eps: 0.434\n",
      "Episode: 518, Reward: 305.0, avg loss: 0.54386, eps: 0.432\n",
      "Episode: 519, Reward: 60.0, avg loss: 1.93350, eps: 0.431\n",
      "Episode: 520, Reward: 75.0, avg loss: 0.45217, eps: 0.430\n",
      "Episode: 521, Reward: 245.0, avg loss: 1.04502, eps: 0.429\n",
      "Episode: 522, Reward: 245.0, avg loss: 1.24588, eps: 0.427\n",
      "Episode: 523, Reward: 55.0, avg loss: 0.82904, eps: 0.426\n",
      "Episode: 524, Reward: 160.0, avg loss: 0.24959, eps: 0.424\n",
      "Episode: 525, Reward: 305.0, avg loss: 0.23546, eps: 0.423\n",
      "Episode: 526, Reward: 240.0, avg loss: 0.68636, eps: 0.421\n",
      "Episode: 527, Reward: 155.0, avg loss: 1.18031, eps: 0.420\n",
      "Episode: 528, Reward: 180.0, avg loss: 0.68650, eps: 0.418\n",
      "Episode: 529, Reward: 75.0, avg loss: 0.35852, eps: 0.418\n",
      "Episode: 530, Reward: 110.0, avg loss: 0.16953, eps: 0.417\n",
      "Episode: 531, Reward: 135.0, avg loss: 0.72020, eps: 0.416\n",
      "Episode: 532, Reward: 145.0, avg loss: 0.31237, eps: 0.415\n",
      "Episode: 533, Reward: 415.0, avg loss: 0.60092, eps: 0.413\n",
      "Episode: 534, Reward: 0.0, avg loss: 0.58384, eps: 0.413\n",
      "Episode: 535, Reward: 290.0, avg loss: 1.68707, eps: 0.411\n",
      "Episode: 536, Reward: 95.0, avg loss: 1.13411, eps: 0.411\n",
      "Episode: 537, Reward: 300.0, avg loss: 2.56102, eps: 0.409\n",
      "Episode: 538, Reward: 75.0, avg loss: 2.81061, eps: 0.408\n",
      "Episode: 539, Reward: 415.0, avg loss: 3.55722, eps: 0.406\n",
      "Episode: 540, Reward: 145.0, avg loss: 1.80046, eps: 0.405\n",
      "Episode: 541, Reward: 105.0, avg loss: 1.16128, eps: 0.404\n",
      "Episode: 542, Reward: 265.0, avg loss: 0.58985, eps: 0.402\n",
      "Episode: 543, Reward: 230.0, avg loss: 1.04004, eps: 0.401\n",
      "Episode: 544, Reward: 110.0, avg loss: 2.04452, eps: 0.399\n",
      "Episode: 545, Reward: 65.0, avg loss: 6.36940, eps: 0.399\n",
      "Episode: 546, Reward: 135.0, avg loss: 1.71256, eps: 0.398\n",
      "Episode: 547, Reward: 180.0, avg loss: 1.68188, eps: 0.396\n",
      "Episode: 548, Reward: 110.0, avg loss: 1.42976, eps: 0.395\n",
      "Episode: 549, Reward: 225.0, avg loss: 0.90641, eps: 0.393\n",
      "Episode: 550, Reward: 140.0, avg loss: 1.20171, eps: 0.391\n",
      "Episode: 551, Reward: 90.0, avg loss: 0.62746, eps: 0.391\n",
      "Episode: 552, Reward: 55.0, avg loss: 0.35041, eps: 0.390\n",
      "Episode: 553, Reward: 20.0, avg loss: 0.32784, eps: 0.389\n",
      "Episode: 554, Reward: 105.0, avg loss: 0.36725, eps: 0.388\n",
      "Episode: 555, Reward: 130.0, avg loss: 0.36678, eps: 0.387\n",
      "Episode: 556, Reward: 90.0, avg loss: 0.87153, eps: 0.386\n",
      "Episode: 557, Reward: 55.0, avg loss: 1.78582, eps: 0.385\n",
      "Episode: 558, Reward: 250.0, avg loss: 1.97883, eps: 0.383\n",
      "Episode: 559, Reward: 330.0, avg loss: 1.89804, eps: 0.381\n",
      "Episode: 560, Reward: 75.0, avg loss: 1.67949, eps: 0.380\n",
      "Episode: 561, Reward: 270.0, avg loss: 3.65668, eps: 0.378\n",
      "Episode: 562, Reward: 110.0, avg loss: 1.88082, eps: 0.377\n",
      "Episode: 563, Reward: 105.0, avg loss: 1.07670, eps: 0.376\n",
      "Episode: 564, Reward: 110.0, avg loss: 0.80349, eps: 0.375\n",
      "Episode: 565, Reward: 55.0, avg loss: 0.72778, eps: 0.374\n",
      "Episode: 566, Reward: 75.0, avg loss: 0.43799, eps: 0.373\n",
      "Episode: 567, Reward: 75.0, avg loss: 0.11056, eps: 0.372\n",
      "Episode: 568, Reward: 140.0, avg loss: 0.20625, eps: 0.370\n",
      "Episode: 569, Reward: 20.0, avg loss: 1.72846, eps: 0.370\n",
      "Episode: 570, Reward: 50.0, avg loss: 0.79808, eps: 0.369\n",
      "Episode: 571, Reward: 65.0, avg loss: 1.12458, eps: 0.367\n",
      "Episode: 572, Reward: 80.0, avg loss: 2.75556, eps: 0.366\n",
      "Episode: 573, Reward: 240.0, avg loss: 2.10752, eps: 0.364\n",
      "Episode: 574, Reward: 230.0, avg loss: 1.18247, eps: 0.363\n",
      "Episode: 575, Reward: 40.0, avg loss: 1.59371, eps: 0.362\n",
      "Episode: 576, Reward: 30.0, avg loss: 1.63496, eps: 0.361\n",
      "Episode: 577, Reward: 155.0, avg loss: 2.34738, eps: 0.360\n",
      "Episode: 578, Reward: 100.0, avg loss: 1.86925, eps: 0.358\n",
      "Episode: 579, Reward: 75.0, avg loss: 1.49126, eps: 0.358\n",
      "Episode: 580, Reward: 535.0, avg loss: 1.90186, eps: 0.355\n",
      "Episode: 581, Reward: 220.0, avg loss: 2.46418, eps: 0.354\n",
      "Episode: 582, Reward: 315.0, avg loss: 2.04413, eps: 0.352\n",
      "Episode: 583, Reward: 85.0, avg loss: 1.94252, eps: 0.351\n",
      "Episode: 584, Reward: 75.0, avg loss: 1.60354, eps: 0.350\n",
      "Episode: 585, Reward: 215.0, avg loss: 3.18280, eps: 0.348\n",
      "Episode: 586, Reward: 250.0, avg loss: 1.50467, eps: 0.346\n",
      "Episode: 587, Reward: 20.0, avg loss: 2.56276, eps: 0.345\n",
      "Episode: 588, Reward: 160.0, avg loss: 4.45349, eps: 0.344\n",
      "Episode: 589, Reward: 165.0, avg loss: 1.07016, eps: 0.343\n",
      "Episode: 590, Reward: 265.0, avg loss: 1.98248, eps: 0.340\n",
      "Episode: 591, Reward: 135.0, avg loss: 2.52139, eps: 0.339\n",
      "Episode: 592, Reward: 275.0, avg loss: 0.97690, eps: 0.337\n",
      "Episode: 593, Reward: 45.0, avg loss: 1.26696, eps: 0.337\n",
      "Episode: 594, Reward: 390.0, avg loss: 2.33750, eps: 0.335\n",
      "Episode: 595, Reward: 50.0, avg loss: 1.56062, eps: 0.334\n",
      "Episode: 596, Reward: 215.0, avg loss: 1.55428, eps: 0.333\n",
      "Episode: 597, Reward: 110.0, avg loss: 1.77994, eps: 0.332\n",
      "Episode: 598, Reward: 75.0, avg loss: 1.01570, eps: 0.331\n",
      "Episode: 599, Reward: 390.0, avg loss: 1.67664, eps: 0.329\n",
      "Episode: 600, Reward: 50.0, avg loss: 1.56450, eps: 0.328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 601, Reward: 230.0, avg loss: 1.26319, eps: 0.325\n",
      "Episode: 602, Reward: 230.0, avg loss: 1.38080, eps: 0.324\n",
      "Episode: 603, Reward: 105.0, avg loss: 1.79633, eps: 0.323\n",
      "Episode: 604, Reward: 110.0, avg loss: 1.14804, eps: 0.322\n",
      "Episode: 605, Reward: 40.0, avg loss: 0.84804, eps: 0.321\n",
      "Episode: 606, Reward: 210.0, avg loss: 0.85105, eps: 0.319\n",
      "Episode: 607, Reward: 60.0, avg loss: 1.66579, eps: 0.318\n",
      "Episode: 608, Reward: 140.0, avg loss: 3.74674, eps: 0.317\n",
      "Episode: 609, Reward: 160.0, avg loss: 3.53752, eps: 0.316\n",
      "Episode: 610, Reward: 110.0, avg loss: 3.73176, eps: 0.315\n",
      "Episode: 611, Reward: 160.0, avg loss: 2.46219, eps: 0.314\n",
      "Episode: 612, Reward: 100.0, avg loss: 2.55712, eps: 0.312\n",
      "Episode: 613, Reward: 150.0, avg loss: 2.35617, eps: 0.311\n",
      "Episode: 614, Reward: 120.0, avg loss: 1.83646, eps: 0.310\n",
      "Episode: 615, Reward: 145.0, avg loss: 0.81105, eps: 0.308\n",
      "Episode: 616, Reward: 150.0, avg loss: 2.23849, eps: 0.307\n",
      "Episode: 617, Reward: 20.0, avg loss: 1.44846, eps: 0.306\n",
      "Episode: 618, Reward: 105.0, avg loss: 0.74821, eps: 0.305\n",
      "Episode: 619, Reward: 255.0, avg loss: 0.88030, eps: 0.303\n",
      "Episode: 620, Reward: 305.0, avg loss: 1.15620, eps: 0.302\n",
      "Episode: 621, Reward: 365.0, avg loss: 1.69975, eps: 0.299\n",
      "Episode: 622, Reward: 125.0, avg loss: 3.17583, eps: 0.298\n",
      "Episode: 623, Reward: 320.0, avg loss: 1.80746, eps: 0.296\n",
      "Episode: 624, Reward: 115.0, avg loss: 3.56335, eps: 0.295\n",
      "Episode: 625, Reward: 185.0, avg loss: 1.55217, eps: 0.293\n",
      "Episode: 626, Reward: 30.0, avg loss: 1.97973, eps: 0.293\n",
      "Episode: 627, Reward: 320.0, avg loss: 1.45871, eps: 0.291\n",
      "Episode: 628, Reward: 120.0, avg loss: 1.93643, eps: 0.290\n",
      "Episode: 629, Reward: 110.0, avg loss: 1.10018, eps: 0.289\n",
      "Episode: 630, Reward: 220.0, avg loss: 0.74942, eps: 0.287\n",
      "Episode: 631, Reward: 105.0, avg loss: 2.89568, eps: 0.285\n",
      "Episode: 632, Reward: 305.0, avg loss: 3.35633, eps: 0.283\n",
      "Episode: 633, Reward: 75.0, avg loss: 5.78318, eps: 0.282\n",
      "Episode: 634, Reward: 390.0, avg loss: 1.84720, eps: 0.280\n",
      "Episode: 635, Reward: 105.0, avg loss: 9.23018, eps: 0.279\n",
      "Episode: 636, Reward: 130.0, avg loss: 6.60605, eps: 0.278\n",
      "Episode: 637, Reward: 40.0, avg loss: 5.13031, eps: 0.277\n",
      "Episode: 638, Reward: 190.0, avg loss: 3.21389, eps: 0.276\n",
      "Episode: 639, Reward: 120.0, avg loss: 2.42044, eps: 0.275\n",
      "Episode: 640, Reward: 160.0, avg loss: 2.45424, eps: 0.273\n",
      "Episode: 641, Reward: 145.0, avg loss: 1.85926, eps: 0.272\n",
      "Episode: 642, Reward: 315.0, avg loss: 1.44929, eps: 0.270\n",
      "Episode: 643, Reward: 30.0, avg loss: 1.21774, eps: 0.269\n",
      "Episode: 644, Reward: 160.0, avg loss: 1.37231, eps: 0.268\n",
      "Episode: 645, Reward: 300.0, avg loss: 0.81053, eps: 0.266\n",
      "Episode: 646, Reward: 195.0, avg loss: 1.71383, eps: 0.264\n",
      "Episode: 647, Reward: 110.0, avg loss: 1.72568, eps: 0.263\n",
      "Episode: 648, Reward: 375.0, avg loss: 1.14070, eps: 0.261\n",
      "Episode: 649, Reward: 115.0, avg loss: 1.93018, eps: 0.260\n",
      "Episode: 650, Reward: 125.0, avg loss: 0.49117, eps: 0.259\n",
      "Episode: 651, Reward: 150.0, avg loss: 0.72320, eps: 0.258\n",
      "Episode: 652, Reward: 435.0, avg loss: 0.77419, eps: 0.256\n",
      "Episode: 653, Reward: 75.0, avg loss: 1.77233, eps: 0.255\n",
      "Episode: 654, Reward: 115.0, avg loss: 2.00179, eps: 0.253\n",
      "Episode: 655, Reward: 30.0, avg loss: 0.88734, eps: 0.253\n",
      "Episode: 656, Reward: 105.0, avg loss: 1.01260, eps: 0.252\n",
      "Episode: 657, Reward: 105.0, avg loss: 0.46208, eps: 0.251\n",
      "Episode: 658, Reward: 130.0, avg loss: 1.17649, eps: 0.249\n",
      "Episode: 659, Reward: 120.0, avg loss: 1.93842, eps: 0.248\n",
      "Episode: 660, Reward: 125.0, avg loss: 0.94916, eps: 0.247\n",
      "Episode: 661, Reward: 490.0, avg loss: 1.09953, eps: 0.245\n",
      "Episode: 662, Reward: 70.0, avg loss: 3.48306, eps: 0.244\n",
      "Episode: 663, Reward: 180.0, avg loss: 0.88056, eps: 0.243\n",
      "Episode: 664, Reward: 25.0, avg loss: 0.38686, eps: 0.242\n",
      "Episode: 665, Reward: 70.0, avg loss: 0.16039, eps: 0.241\n",
      "Episode: 666, Reward: 235.0, avg loss: 0.77574, eps: 0.240\n",
      "Episode: 667, Reward: 105.0, avg loss: 1.48141, eps: 0.239\n",
      "Episode: 668, Reward: 175.0, avg loss: 0.66487, eps: 0.237\n",
      "Episode: 669, Reward: 220.0, avg loss: 0.70620, eps: 0.236\n",
      "Episode: 670, Reward: 190.0, avg loss: 1.96578, eps: 0.234\n",
      "Episode: 671, Reward: 155.0, avg loss: 4.62447, eps: 0.233\n",
      "Episode: 672, Reward: 65.0, avg loss: 13.23873, eps: 0.232\n",
      "Episode: 673, Reward: 95.0, avg loss: 1.56922, eps: 0.231\n",
      "Episode: 674, Reward: 400.0, avg loss: 1.15277, eps: 0.230\n",
      "Episode: 675, Reward: 135.0, avg loss: 0.85952, eps: 0.229\n",
      "Episode: 676, Reward: 190.0, avg loss: 1.05661, eps: 0.227\n",
      "Episode: 677, Reward: 65.0, avg loss: 1.15549, eps: 0.227\n",
      "Episode: 678, Reward: 230.0, avg loss: 4.98925, eps: 0.225\n",
      "Episode: 679, Reward: 70.0, avg loss: 4.29604, eps: 0.224\n",
      "Episode: 680, Reward: 105.0, avg loss: 2.88235, eps: 0.223\n",
      "Episode: 681, Reward: 395.0, avg loss: 1.90201, eps: 0.220\n",
      "Episode: 682, Reward: 60.0, avg loss: 3.69965, eps: 0.219\n",
      "Episode: 683, Reward: 175.0, avg loss: 1.00575, eps: 0.218\n",
      "Episode: 684, Reward: 30.0, avg loss: 0.52544, eps: 0.217\n",
      "Episode: 685, Reward: 110.0, avg loss: 0.23851, eps: 0.216\n",
      "Episode: 686, Reward: 110.0, avg loss: 0.89934, eps: 0.215\n",
      "Episode: 687, Reward: 60.0, avg loss: 0.77692, eps: 0.214\n",
      "Episode: 688, Reward: 125.0, avg loss: 0.43749, eps: 0.213\n",
      "Episode: 689, Reward: 265.0, avg loss: 2.84454, eps: 0.210\n",
      "Episode: 690, Reward: 10.0, avg loss: 2.17522, eps: 0.210\n",
      "Episode: 691, Reward: 120.0, avg loss: 2.26989, eps: 0.209\n",
      "Episode: 692, Reward: 90.0, avg loss: 2.01823, eps: 0.208\n",
      "Episode: 693, Reward: 60.0, avg loss: 0.16477, eps: 0.207\n",
      "Episode: 694, Reward: 130.0, avg loss: 0.13194, eps: 0.205\n",
      "Episode: 695, Reward: 150.0, avg loss: 0.20697, eps: 0.204\n",
      "Episode: 696, Reward: 75.0, avg loss: 0.14777, eps: 0.203\n",
      "Episode: 697, Reward: 250.0, avg loss: 0.10061, eps: 0.201\n",
      "Episode: 698, Reward: 100.0, avg loss: 0.16131, eps: 0.200\n",
      "Episode: 699, Reward: 140.0, avg loss: 0.13299, eps: 0.199\n",
      "Episode: 700, Reward: 150.0, avg loss: 0.04491, eps: 0.197\n",
      "Episode: 701, Reward: 190.0, avg loss: 0.01840, eps: 0.196\n",
      "Episode: 702, Reward: 195.0, avg loss: 0.02821, eps: 0.195\n",
      "Episode: 703, Reward: 120.0, avg loss: 0.04785, eps: 0.193\n",
      "Episode: 704, Reward: 115.0, avg loss: 0.02974, eps: 0.192\n",
      "Episode: 705, Reward: 15.0, avg loss: 0.00584, eps: 0.191\n",
      "Episode: 706, Reward: 220.0, avg loss: 0.99449, eps: 0.100\n",
      "Episode: 707, Reward: 165.0, avg loss: 1.14336, eps: 0.100\n",
      "Episode: 708, Reward: 170.0, avg loss: 0.26682, eps: 0.100\n",
      "Episode: 709, Reward: 150.0, avg loss: 0.03381, eps: 0.100\n",
      "Episode: 710, Reward: 125.0, avg loss: 0.06550, eps: 0.100\n",
      "Episode: 711, Reward: 275.0, avg loss: 0.03437, eps: 0.100\n",
      "Episode: 712, Reward: 45.0, avg loss: 0.03136, eps: 0.100\n",
      "Episode: 713, Reward: 75.0, avg loss: 0.01974, eps: 0.100\n",
      "Episode: 714, Reward: 355.0, avg loss: 0.05522, eps: 0.100\n",
      "Episode: 715, Reward: 345.0, avg loss: 0.03249, eps: 0.100\n",
      "Episode: 716, Reward: 105.0, avg loss: 0.02272, eps: 0.100\n",
      "Episode: 717, Reward: 160.0, avg loss: 0.02905, eps: 0.100\n",
      "Episode: 718, Reward: 225.0, avg loss: 0.03993, eps: 0.100\n",
      "Episode: 719, Reward: 470.0, avg loss: 2.91011, eps: 0.100\n",
      "Episode: 720, Reward: 50.0, avg loss: 0.80087, eps: 0.100\n",
      "Episode: 721, Reward: 50.0, avg loss: 0.14031, eps: 0.100\n",
      "Episode: 722, Reward: 75.0, avg loss: 0.01544, eps: 0.100\n",
      "Episode: 723, Reward: 185.0, avg loss: 0.06625, eps: 0.100\n",
      "Episode: 724, Reward: 415.0, avg loss: 0.16692, eps: 0.100\n",
      "Episode: 725, Reward: 515.0, avg loss: 0.60665, eps: 0.100\n",
      "Episode: 726, Reward: 75.0, avg loss: 1.42317, eps: 0.100\n",
      "Episode: 727, Reward: 600.0, avg loss: 1.94375, eps: 0.100\n",
      "Episode: 728, Reward: 160.0, avg loss: 2.07481, eps: 0.100\n",
      "Episode: 729, Reward: 250.0, avg loss: 0.38859, eps: 0.100\n",
      "Episode: 730, Reward: 320.0, avg loss: 1.19461, eps: 0.100\n",
      "Episode: 731, Reward: 210.0, avg loss: 0.75683, eps: 0.100\n",
      "Episode: 732, Reward: 140.0, avg loss: 0.01364, eps: 0.100\n",
      "Episode: 733, Reward: 60.0, avg loss: 0.00964, eps: 0.100\n",
      "Episode: 734, Reward: 405.0, avg loss: 0.44744, eps: 0.100\n",
      "Episode: 735, Reward: 490.0, avg loss: 0.12459, eps: 0.100\n",
      "Episode: 736, Reward: 265.0, avg loss: 0.11834, eps: 0.100\n",
      "Episode: 737, Reward: 235.0, avg loss: 2.83610, eps: 0.100\n",
      "Episode: 738, Reward: 400.0, avg loss: 0.23242, eps: 0.100\n",
      "Episode: 739, Reward: 45.0, avg loss: 0.02421, eps: 0.100\n",
      "Episode: 740, Reward: 105.0, avg loss: 0.01370, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 741, Reward: 95.0, avg loss: 0.01610, eps: 0.100\n",
      "Episode: 742, Reward: 195.0, avg loss: 0.04013, eps: 0.100\n",
      "Episode: 743, Reward: 120.0, avg loss: 0.04256, eps: 0.100\n",
      "Episode: 744, Reward: 290.0, avg loss: 3.93087, eps: 0.100\n",
      "Episode: 745, Reward: 105.0, avg loss: 4.38098, eps: 0.100\n",
      "Episode: 746, Reward: 245.0, avg loss: 0.81056, eps: 0.100\n",
      "Episode: 747, Reward: 160.0, avg loss: 0.11135, eps: 0.100\n",
      "Episode: 748, Reward: 215.0, avg loss: 0.02205, eps: 0.100\n",
      "Episode: 749, Reward: 210.0, avg loss: 0.03264, eps: 0.100\n",
      "Episode: 750, Reward: 160.0, avg loss: 0.02881, eps: 0.100\n",
      "Episode: 751, Reward: 125.0, avg loss: 0.01935, eps: 0.100\n",
      "Episode: 752, Reward: 75.0, avg loss: 0.02237, eps: 0.100\n",
      "Episode: 753, Reward: 150.0, avg loss: 1.05290, eps: 0.100\n",
      "Episode: 754, Reward: 115.0, avg loss: 3.37121, eps: 0.100\n",
      "Episode: 755, Reward: 20.0, avg loss: 1.52653, eps: 0.100\n",
      "Episode: 756, Reward: 145.0, avg loss: 1.40881, eps: 0.100\n",
      "Episode: 757, Reward: 270.0, avg loss: 4.10719, eps: 0.100\n",
      "Episode: 758, Reward: 140.0, avg loss: 4.81107, eps: 0.100\n",
      "Episode: 759, Reward: 190.0, avg loss: 2.08905, eps: 0.100\n",
      "Episode: 760, Reward: 70.0, avg loss: 0.99464, eps: 0.100\n",
      "Episode: 761, Reward: 450.0, avg loss: 0.36786, eps: 0.100\n",
      "Episode: 762, Reward: 100.0, avg loss: 0.62584, eps: 0.100\n",
      "Episode: 763, Reward: 105.0, avg loss: 0.05020, eps: 0.100\n",
      "Episode: 764, Reward: 95.0, avg loss: 0.01171, eps: 0.100\n",
      "Episode: 765, Reward: 140.0, avg loss: 0.01284, eps: 0.100\n",
      "Episode: 766, Reward: 175.0, avg loss: 0.02484, eps: 0.100\n",
      "Episode: 767, Reward: 335.0, avg loss: 0.04831, eps: 0.100\n",
      "Episode: 768, Reward: 290.0, avg loss: 0.05612, eps: 0.100\n",
      "Episode: 769, Reward: 205.0, avg loss: 0.02923, eps: 0.100\n",
      "Episode: 770, Reward: 320.0, avg loss: 0.02968, eps: 0.100\n",
      "Episode: 771, Reward: 135.0, avg loss: 0.03104, eps: 0.100\n",
      "Episode: 772, Reward: 165.0, avg loss: 0.01429, eps: 0.100\n",
      "Episode: 773, Reward: 445.0, avg loss: 0.04762, eps: 0.100\n",
      "Episode: 774, Reward: 165.0, avg loss: 0.04959, eps: 0.100\n",
      "Episode: 775, Reward: 145.0, avg loss: 0.05361, eps: 0.100\n",
      "Episode: 776, Reward: 115.0, avg loss: 0.01722, eps: 0.100\n",
      "Episode: 777, Reward: 200.0, avg loss: 0.02634, eps: 0.100\n",
      "Episode: 778, Reward: 215.0, avg loss: 0.05958, eps: 0.100\n",
      "Episode: 779, Reward: 55.0, avg loss: 0.03711, eps: 0.100\n",
      "Episode: 780, Reward: 380.0, avg loss: 2.10393, eps: 0.100\n",
      "Episode: 781, Reward: 200.0, avg loss: 1.97625, eps: 0.100\n",
      "Episode: 782, Reward: 75.0, avg loss: 0.28132, eps: 0.100\n",
      "Episode: 783, Reward: 135.0, avg loss: 0.48791, eps: 0.100\n",
      "Episode: 784, Reward: 185.0, avg loss: 0.19505, eps: 0.100\n",
      "Episode: 785, Reward: 105.0, avg loss: 0.04430, eps: 0.100\n",
      "Episode: 786, Reward: 175.0, avg loss: 0.02390, eps: 0.100\n",
      "Episode: 787, Reward: 255.0, avg loss: 0.06635, eps: 0.100\n",
      "Episode: 788, Reward: 310.0, avg loss: 2.41502, eps: 0.100\n",
      "Episode: 789, Reward: 395.0, avg loss: 24.52292, eps: 0.100\n",
      "Episode: 790, Reward: 185.0, avg loss: 0.13059, eps: 0.100\n",
      "Episode: 791, Reward: 120.0, avg loss: 0.02639, eps: 0.100\n",
      "Episode: 792, Reward: 105.0, avg loss: 0.02226, eps: 0.100\n",
      "Episode: 793, Reward: 210.0, avg loss: 0.04017, eps: 0.100\n",
      "Episode: 794, Reward: 345.0, avg loss: 0.04993, eps: 0.100\n",
      "Episode: 795, Reward: 200.0, avg loss: 0.02028, eps: 0.100\n",
      "Episode: 796, Reward: 60.0, avg loss: 0.02751, eps: 0.100\n",
      "Episode: 797, Reward: 140.0, avg loss: 0.01384, eps: 0.100\n",
      "Episode: 798, Reward: 125.0, avg loss: 0.01510, eps: 0.100\n",
      "Episode: 799, Reward: 110.0, avg loss: 0.01252, eps: 0.100\n",
      "Episode: 800, Reward: 655.0, avg loss: 0.09468, eps: 0.100\n",
      "Episode: 801, Reward: 50.0, avg loss: 0.06810, eps: 0.100\n",
      "Episode: 802, Reward: 130.0, avg loss: 0.02038, eps: 0.100\n",
      "Episode: 803, Reward: 265.0, avg loss: 0.03547, eps: 0.100\n",
      "Episode: 804, Reward: 70.0, avg loss: 0.03178, eps: 0.100\n",
      "Episode: 805, Reward: 125.0, avg loss: 0.03054, eps: 0.100\n",
      "Episode: 806, Reward: 185.0, avg loss: 0.01736, eps: 0.100\n",
      "Episode: 807, Reward: 150.0, avg loss: 0.03222, eps: 0.100\n",
      "Episode: 808, Reward: 235.0, avg loss: 0.02659, eps: 0.100\n",
      "Episode: 809, Reward: 250.0, avg loss: 0.01917, eps: 0.100\n",
      "Episode: 810, Reward: 115.0, avg loss: 0.01068, eps: 0.100\n",
      "Episode: 811, Reward: 255.0, avg loss: 0.04386, eps: 0.100\n",
      "Episode: 812, Reward: 100.0, avg loss: 0.02629, eps: 0.100\n",
      "Episode: 813, Reward: 130.0, avg loss: 0.01754, eps: 0.100\n",
      "Episode: 814, Reward: 165.0, avg loss: 0.04185, eps: 0.100\n",
      "Episode: 815, Reward: 185.0, avg loss: 0.03096, eps: 0.100\n",
      "Episode: 816, Reward: 170.0, avg loss: 0.02584, eps: 0.100\n",
      "Episode: 817, Reward: 330.0, avg loss: 0.06288, eps: 0.100\n",
      "Episode: 818, Reward: 305.0, avg loss: 0.03094, eps: 0.100\n",
      "Episode: 819, Reward: 235.0, avg loss: 0.03026, eps: 0.100\n",
      "Episode: 820, Reward: 90.0, avg loss: 0.05152, eps: 0.100\n",
      "Episode: 821, Reward: 120.0, avg loss: 0.02492, eps: 0.100\n",
      "Episode: 822, Reward: 125.0, avg loss: 0.02709, eps: 0.100\n",
      "Episode: 823, Reward: 115.0, avg loss: 0.01853, eps: 0.100\n",
      "Episode: 824, Reward: 155.0, avg loss: 0.02811, eps: 0.100\n",
      "Episode: 825, Reward: 225.0, avg loss: 0.01891, eps: 0.100\n",
      "Episode: 826, Reward: 190.0, avg loss: 0.02559, eps: 0.100\n",
      "Episode: 827, Reward: 150.0, avg loss: 0.04350, eps: 0.100\n",
      "Episode: 828, Reward: 140.0, avg loss: 0.03682, eps: 0.100\n",
      "Episode: 829, Reward: 220.0, avg loss: 0.03493, eps: 0.100\n",
      "Episode: 830, Reward: 75.0, avg loss: 0.00927, eps: 0.100\n",
      "Episode: 831, Reward: 290.0, avg loss: 0.03648, eps: 0.100\n",
      "Episode: 832, Reward: 140.0, avg loss: 0.04396, eps: 0.100\n",
      "Episode: 833, Reward: 80.0, avg loss: 0.02788, eps: 0.100\n",
      "Episode: 834, Reward: 90.0, avg loss: 0.03072, eps: 0.100\n",
      "Episode: 835, Reward: 90.0, avg loss: 0.03329, eps: 0.100\n",
      "Episode: 836, Reward: 140.0, avg loss: 0.03145, eps: 0.100\n",
      "Episode: 837, Reward: 335.0, avg loss: 0.01681, eps: 0.100\n",
      "Episode: 838, Reward: 110.0, avg loss: 0.02497, eps: 0.100\n",
      "Episode: 839, Reward: 120.0, avg loss: 0.02040, eps: 0.100\n",
      "Episode: 840, Reward: 165.0, avg loss: 0.05321, eps: 0.100\n",
      "Episode: 841, Reward: 245.0, avg loss: 0.05638, eps: 0.100\n",
      "Episode: 842, Reward: 540.0, avg loss: 0.18188, eps: 0.100\n",
      "Episode: 843, Reward: 245.0, avg loss: 0.04088, eps: 0.100\n",
      "Episode: 844, Reward: 235.0, avg loss: 0.05991, eps: 0.100\n",
      "Episode: 845, Reward: 1100.0, avg loss: 0.33936, eps: 0.100\n",
      "Episode: 846, Reward: 160.0, avg loss: 1.63828, eps: 0.100\n",
      "Episode: 847, Reward: 170.0, avg loss: 0.04034, eps: 0.100\n",
      "Episode: 848, Reward: 275.0, avg loss: 0.03501, eps: 0.100\n",
      "Episode: 849, Reward: 200.0, avg loss: 0.04158, eps: 0.100\n",
      "Episode: 850, Reward: 90.0, avg loss: 0.02614, eps: 0.100\n",
      "Episode: 851, Reward: 155.0, avg loss: 0.02814, eps: 0.100\n",
      "Episode: 852, Reward: 75.0, avg loss: 0.00761, eps: 0.100\n",
      "Episode: 853, Reward: 135.0, avg loss: 0.96304, eps: 0.100\n",
      "Episode: 854, Reward: 210.0, avg loss: 0.05008, eps: 0.100\n",
      "Episode: 855, Reward: 30.0, avg loss: 0.01860, eps: 0.100\n",
      "Episode: 856, Reward: 140.0, avg loss: 0.01809, eps: 0.100\n",
      "Episode: 857, Reward: 275.0, avg loss: 0.36975, eps: 0.100\n",
      "Episode: 858, Reward: 375.0, avg loss: 0.12702, eps: 0.100\n",
      "Episode: 859, Reward: 410.0, avg loss: 0.05482, eps: 0.100\n",
      "Episode: 860, Reward: 170.0, avg loss: 0.03024, eps: 0.100\n",
      "Episode: 861, Reward: 120.0, avg loss: 0.01574, eps: 0.100\n",
      "Episode: 862, Reward: 145.0, avg loss: 0.01197, eps: 0.100\n",
      "Episode: 863, Reward: 225.0, avg loss: 0.03035, eps: 0.100\n",
      "Episode: 864, Reward: 210.0, avg loss: 0.04728, eps: 0.100\n",
      "Episode: 865, Reward: 155.0, avg loss: 0.03801, eps: 0.100\n",
      "Episode: 866, Reward: 195.0, avg loss: 0.04462, eps: 0.100\n",
      "Episode: 867, Reward: 70.0, avg loss: 0.04900, eps: 0.100\n",
      "Episode: 868, Reward: 235.0, avg loss: 0.04512, eps: 0.100\n",
      "Episode: 869, Reward: 75.0, avg loss: 0.04353, eps: 0.100\n",
      "Episode: 870, Reward: 300.0, avg loss: 0.02991, eps: 0.100\n",
      "Episode: 871, Reward: 420.0, avg loss: 0.03944, eps: 0.100\n",
      "Episode: 872, Reward: 425.0, avg loss: 0.07386, eps: 0.100\n",
      "Episode: 873, Reward: 155.0, avg loss: 0.03883, eps: 0.100\n",
      "Episode: 874, Reward: 130.0, avg loss: 0.03594, eps: 0.100\n",
      "Episode: 875, Reward: 460.0, avg loss: 0.04103, eps: 0.100\n",
      "Episode: 876, Reward: 170.0, avg loss: 0.02993, eps: 0.100\n",
      "Episode: 877, Reward: 75.0, avg loss: 0.03108, eps: 0.100\n",
      "Episode: 878, Reward: 110.0, avg loss: 0.02457, eps: 0.100\n",
      "Episode: 879, Reward: 25.0, avg loss: 0.00263, eps: 0.100\n",
      "Episode: 880, Reward: 210.0, avg loss: 0.01598, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 881, Reward: 110.0, avg loss: 0.03834, eps: 0.100\n",
      "Episode: 882, Reward: 110.0, avg loss: 0.02432, eps: 0.100\n",
      "Episode: 883, Reward: 295.0, avg loss: 1.24987, eps: 0.100\n",
      "Episode: 884, Reward: 180.0, avg loss: 0.20338, eps: 0.100\n",
      "Episode: 885, Reward: 185.0, avg loss: 0.09677, eps: 0.100\n",
      "Episode: 886, Reward: 110.0, avg loss: 0.02385, eps: 0.100\n",
      "Episode: 887, Reward: 175.0, avg loss: 0.01601, eps: 0.100\n",
      "Episode: 888, Reward: 110.0, avg loss: 0.02879, eps: 0.100\n",
      "Episode: 889, Reward: 170.0, avg loss: 0.02316, eps: 0.100\n",
      "Episode: 890, Reward: 200.0, avg loss: 0.06199, eps: 0.100\n",
      "Episode: 891, Reward: 60.0, avg loss: 0.01604, eps: 0.100\n",
      "Episode: 892, Reward: 30.0, avg loss: 0.01380, eps: 0.100\n",
      "Episode: 893, Reward: 55.0, avg loss: 0.01249, eps: 0.100\n",
      "Episode: 894, Reward: 30.0, avg loss: 0.01561, eps: 0.100\n",
      "Episode: 895, Reward: 40.0, avg loss: 0.00564, eps: 0.100\n",
      "Episode: 896, Reward: 220.0, avg loss: 0.02909, eps: 0.100\n",
      "Episode: 897, Reward: 60.0, avg loss: 0.01599, eps: 0.100\n",
      "Episode: 898, Reward: 15.0, avg loss: 0.01045, eps: 0.100\n",
      "Episode: 899, Reward: 225.0, avg loss: 0.01798, eps: 0.100\n",
      "Episode: 900, Reward: 405.0, avg loss: 0.01551, eps: 0.100\n",
      "Episode: 901, Reward: 75.0, avg loss: 0.01468, eps: 0.100\n",
      "Episode: 902, Reward: 130.0, avg loss: 0.01411, eps: 0.100\n",
      "Episode: 903, Reward: 160.0, avg loss: 0.01230, eps: 0.100\n",
      "Episode: 904, Reward: 75.0, avg loss: 0.01377, eps: 0.100\n",
      "Episode: 905, Reward: 210.0, avg loss: 0.03957, eps: 0.100\n",
      "Episode: 906, Reward: 180.0, avg loss: 0.04041, eps: 0.100\n",
      "Episode: 907, Reward: 155.0, avg loss: 0.03971, eps: 0.100\n",
      "Episode: 908, Reward: 155.0, avg loss: 0.02809, eps: 0.100\n",
      "Episode: 909, Reward: 310.0, avg loss: 0.02163, eps: 0.100\n",
      "Episode: 910, Reward: 265.0, avg loss: 0.03827, eps: 0.100\n",
      "Episode: 911, Reward: 210.0, avg loss: 0.04612, eps: 0.100\n",
      "Episode: 912, Reward: 170.0, avg loss: 0.02585, eps: 0.100\n",
      "Episode: 913, Reward: 395.0, avg loss: 0.05568, eps: 0.100\n",
      "Episode: 914, Reward: 150.0, avg loss: 0.02851, eps: 0.100\n",
      "Episode: 915, Reward: 415.0, avg loss: 0.02684, eps: 0.100\n",
      "Episode: 916, Reward: 275.0, avg loss: 0.03964, eps: 0.100\n",
      "Episode: 917, Reward: 80.0, avg loss: 0.02728, eps: 0.100\n",
      "Episode: 918, Reward: 325.0, avg loss: 0.02385, eps: 0.100\n",
      "Episode: 919, Reward: 205.0, avg loss: 0.01333, eps: 0.100\n",
      "Episode: 920, Reward: 170.0, avg loss: 0.00924, eps: 0.100\n",
      "Episode: 921, Reward: 95.0, avg loss: 0.03262, eps: 0.100\n",
      "Episode: 922, Reward: 160.0, avg loss: 0.02731, eps: 0.100\n",
      "Episode: 923, Reward: 240.0, avg loss: 0.06148, eps: 0.100\n",
      "Episode: 924, Reward: 280.0, avg loss: 0.05177, eps: 0.100\n",
      "Episode: 925, Reward: 450.0, avg loss: 0.03706, eps: 0.100\n",
      "Episode: 926, Reward: 90.0, avg loss: 0.07257, eps: 0.100\n",
      "Episode: 927, Reward: 185.0, avg loss: 0.03139, eps: 0.100\n",
      "Episode: 928, Reward: 200.0, avg loss: 0.02453, eps: 0.100\n",
      "Episode: 929, Reward: 350.0, avg loss: 0.04317, eps: 0.100\n",
      "Episode: 930, Reward: 55.0, avg loss: 0.00809, eps: 0.100\n",
      "Episode: 931, Reward: 130.0, avg loss: 0.01647, eps: 0.100\n",
      "Episode: 932, Reward: 105.0, avg loss: 0.03623, eps: 0.100\n",
      "Episode: 933, Reward: 110.0, avg loss: 0.02565, eps: 0.100\n",
      "Episode: 934, Reward: 205.0, avg loss: 0.02279, eps: 0.100\n",
      "Episode: 935, Reward: 215.0, avg loss: 0.02854, eps: 0.100\n",
      "Episode: 936, Reward: 195.0, avg loss: 0.04751, eps: 0.100\n",
      "Episode: 937, Reward: 245.0, avg loss: 0.03417, eps: 0.100\n",
      "Episode: 938, Reward: 205.0, avg loss: 0.03531, eps: 0.100\n",
      "Episode: 939, Reward: 180.0, avg loss: 0.02492, eps: 0.100\n",
      "Episode: 940, Reward: 50.0, avg loss: 0.02120, eps: 0.100\n",
      "Episode: 941, Reward: 95.0, avg loss: 0.01789, eps: 0.100\n",
      "Episode: 942, Reward: 160.0, avg loss: 0.02437, eps: 0.100\n",
      "Episode: 943, Reward: 210.0, avg loss: 0.02433, eps: 0.100\n",
      "Episode: 944, Reward: 455.0, avg loss: 0.04682, eps: 0.100\n",
      "Episode: 945, Reward: 135.0, avg loss: 0.03631, eps: 0.100\n",
      "Episode: 946, Reward: 285.0, avg loss: 0.01630, eps: 0.100\n",
      "Episode: 947, Reward: 75.0, avg loss: 0.00956, eps: 0.100\n",
      "Episode: 948, Reward: 50.0, avg loss: 0.02246, eps: 0.100\n",
      "Episode: 949, Reward: 35.0, avg loss: 0.01522, eps: 0.100\n",
      "Episode: 950, Reward: 135.0, avg loss: 0.01609, eps: 0.100\n",
      "Episode: 951, Reward: 75.0, avg loss: 0.01067, eps: 0.100\n",
      "Episode: 952, Reward: 35.0, avg loss: 0.01679, eps: 0.100\n",
      "Episode: 953, Reward: 225.0, avg loss: 0.01818, eps: 0.100\n",
      "Episode: 954, Reward: 95.0, avg loss: 0.01490, eps: 0.100\n",
      "Episode: 955, Reward: 270.0, avg loss: 0.02325, eps: 0.100\n",
      "Episode: 956, Reward: 100.0, avg loss: 0.03838, eps: 0.100\n",
      "Episode: 957, Reward: 260.0, avg loss: 0.03519, eps: 0.100\n",
      "Episode: 958, Reward: 415.0, avg loss: 0.04834, eps: 0.100\n",
      "Episode: 959, Reward: 355.0, avg loss: 0.05360, eps: 0.100\n",
      "Episode: 960, Reward: 130.0, avg loss: 0.03435, eps: 0.100\n",
      "Episode: 961, Reward: 240.0, avg loss: 0.02936, eps: 0.100\n",
      "Episode: 962, Reward: 365.0, avg loss: 0.06703, eps: 0.100\n",
      "Episode: 963, Reward: 170.0, avg loss: 0.06387, eps: 0.100\n",
      "Episode: 964, Reward: 180.0, avg loss: 0.02623, eps: 0.100\n",
      "Episode: 965, Reward: 215.0, avg loss: 0.02505, eps: 0.100\n",
      "Episode: 966, Reward: 240.0, avg loss: 0.03245, eps: 0.100\n",
      "Episode: 967, Reward: 60.0, avg loss: 0.04526, eps: 0.100\n",
      "Episode: 968, Reward: 170.0, avg loss: 0.02400, eps: 0.100\n",
      "Episode: 969, Reward: 115.0, avg loss: 0.01938, eps: 0.100\n",
      "Episode: 970, Reward: 50.0, avg loss: 0.03159, eps: 0.100\n",
      "Episode: 971, Reward: 275.0, avg loss: 0.02724, eps: 0.100\n",
      "Episode: 972, Reward: 150.0, avg loss: 0.03613, eps: 0.100\n",
      "Episode: 973, Reward: 110.0, avg loss: 0.02248, eps: 0.100\n",
      "Episode: 974, Reward: 495.0, avg loss: 0.04734, eps: 0.100\n",
      "Episode: 975, Reward: 225.0, avg loss: 0.04331, eps: 0.100\n",
      "Episode: 976, Reward: 135.0, avg loss: 0.01706, eps: 0.100\n",
      "Episode: 977, Reward: 205.0, avg loss: 0.03010, eps: 0.100\n",
      "Episode: 978, Reward: 220.0, avg loss: 0.05210, eps: 0.100\n",
      "Episode: 979, Reward: 135.0, avg loss: 0.02496, eps: 0.100\n",
      "Episode: 980, Reward: 140.0, avg loss: 0.01964, eps: 0.100\n",
      "Episode: 981, Reward: 150.0, avg loss: 0.01777, eps: 0.100\n",
      "Episode: 982, Reward: 15.0, avg loss: 0.00450, eps: 0.100\n",
      "Episode: 983, Reward: 440.0, avg loss: 0.06386, eps: 0.100\n",
      "Episode: 984, Reward: 95.0, avg loss: 0.07664, eps: 0.100\n",
      "Episode: 985, Reward: 195.0, avg loss: 0.01501, eps: 0.100\n",
      "Episode: 986, Reward: 210.0, avg loss: 0.03309, eps: 0.100\n",
      "Episode: 987, Reward: 20.0, avg loss: 0.01859, eps: 0.100\n",
      "Episode: 988, Reward: 35.0, avg loss: 0.00518, eps: 0.100\n",
      "Episode: 989, Reward: 265.0, avg loss: 0.03721, eps: 0.100\n",
      "Episode: 990, Reward: 210.0, avg loss: 0.01977, eps: 0.100\n",
      "Episode: 991, Reward: 155.0, avg loss: 0.02998, eps: 0.100\n",
      "Episode: 992, Reward: 310.0, avg loss: 0.01934, eps: 0.100\n",
      "Episode: 993, Reward: 180.0, avg loss: 0.04897, eps: 0.100\n",
      "Episode: 994, Reward: 210.0, avg loss: 0.01745, eps: 0.100\n",
      "Episode: 995, Reward: 240.0, avg loss: 0.03133, eps: 0.100\n",
      "Episode: 996, Reward: 160.0, avg loss: 0.02074, eps: 0.100\n",
      "Episode: 997, Reward: 185.0, avg loss: 0.02513, eps: 0.100\n",
      "Episode: 998, Reward: 105.0, avg loss: 0.02415, eps: 0.100\n",
      "Episode: 999, Reward: 175.0, avg loss: 0.01221, eps: 0.100\n",
      "Episode: 1000, Reward: 165.0, avg loss: 0.03398, eps: 0.100\n",
      "Episode: 1001, Reward: 435.0, avg loss: 0.06504, eps: 0.100\n",
      "Episode: 1002, Reward: 110.0, avg loss: 0.04697, eps: 0.100\n",
      "Episode: 1003, Reward: 130.0, avg loss: 0.02161, eps: 0.100\n",
      "Episode: 1004, Reward: 140.0, avg loss: 0.05631, eps: 0.100\n",
      "Episode: 1005, Reward: 290.0, avg loss: 0.05374, eps: 0.100\n",
      "Episode: 1006, Reward: 225.0, avg loss: 0.04702, eps: 0.100\n",
      "Episode: 1007, Reward: 75.0, avg loss: 0.02137, eps: 0.100\n",
      "Episode: 1008, Reward: 230.0, avg loss: 0.03463, eps: 0.100\n",
      "Episode: 1009, Reward: 505.0, avg loss: 0.06750, eps: 0.100\n",
      "Episode: 1010, Reward: 75.0, avg loss: 0.02689, eps: 0.100\n",
      "Episode: 1011, Reward: 490.0, avg loss: 0.04399, eps: 0.100\n",
      "Episode: 1012, Reward: 180.0, avg loss: 0.02382, eps: 0.100\n",
      "Episode: 1013, Reward: 345.0, avg loss: 0.02510, eps: 0.100\n",
      "Episode: 1014, Reward: 325.0, avg loss: 0.03839, eps: 0.100\n",
      "Episode: 1015, Reward: 185.0, avg loss: 0.02560, eps: 0.100\n",
      "Episode: 1016, Reward: 205.0, avg loss: 0.03431, eps: 0.100\n",
      "Episode: 1017, Reward: 310.0, avg loss: 0.05558, eps: 0.100\n",
      "Episode: 1018, Reward: 260.0, avg loss: 0.04346, eps: 0.100\n",
      "Episode: 1019, Reward: 50.0, avg loss: 0.01855, eps: 0.100\n",
      "Episode: 1020, Reward: 50.0, avg loss: 0.01869, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1021, Reward: 245.0, avg loss: 0.04063, eps: 0.100\n",
      "Episode: 1022, Reward: 195.0, avg loss: 0.02167, eps: 0.100\n",
      "Episode: 1023, Reward: 200.0, avg loss: 0.04309, eps: 0.100\n",
      "Episode: 1024, Reward: 140.0, avg loss: 0.03101, eps: 0.100\n",
      "Episode: 1025, Reward: 185.0, avg loss: 0.04291, eps: 0.100\n",
      "Episode: 1026, Reward: 215.0, avg loss: 0.05162, eps: 0.100\n",
      "Episode: 1027, Reward: 160.0, avg loss: 0.01906, eps: 0.100\n",
      "Episode: 1028, Reward: 110.0, avg loss: 0.00820, eps: 0.100\n",
      "Episode: 1029, Reward: 105.0, avg loss: 0.01559, eps: 0.100\n",
      "Episode: 1030, Reward: 175.0, avg loss: 0.02449, eps: 0.100\n",
      "Episode: 1031, Reward: 405.0, avg loss: 0.03147, eps: 0.100\n",
      "Episode: 1032, Reward: 150.0, avg loss: 0.03743, eps: 0.100\n",
      "Episode: 1033, Reward: 365.0, avg loss: 0.04478, eps: 0.100\n",
      "Episode: 1034, Reward: 205.0, avg loss: 0.03320, eps: 0.100\n",
      "Episode: 1035, Reward: 115.0, avg loss: 0.02176, eps: 0.100\n",
      "Episode: 1036, Reward: 105.0, avg loss: 0.00827, eps: 0.100\n",
      "Episode: 1037, Reward: 80.0, avg loss: 0.00500, eps: 0.100\n",
      "Episode: 1038, Reward: 280.0, avg loss: 0.04463, eps: 0.100\n",
      "Episode: 1039, Reward: 245.0, avg loss: 0.04182, eps: 0.100\n",
      "Episode: 1040, Reward: 120.0, avg loss: 0.02410, eps: 0.100\n",
      "Episode: 1041, Reward: 435.0, avg loss: 0.05185, eps: 0.100\n",
      "Episode: 1042, Reward: 500.0, avg loss: 0.05016, eps: 0.100\n",
      "Episode: 1043, Reward: 45.0, avg loss: 0.02592, eps: 0.100\n",
      "Episode: 1044, Reward: 355.0, avg loss: 0.01681, eps: 0.100\n",
      "Episode: 1045, Reward: 95.0, avg loss: 0.00726, eps: 0.100\n",
      "Episode: 1046, Reward: 570.0, avg loss: 0.03464, eps: 0.100\n",
      "Episode: 1047, Reward: 345.0, avg loss: 0.04381, eps: 0.100\n",
      "Episode: 1048, Reward: 185.0, avg loss: 0.03827, eps: 0.100\n",
      "Episode: 1049, Reward: 165.0, avg loss: 0.02512, eps: 0.100\n",
      "Episode: 1050, Reward: 320.0, avg loss: 0.03148, eps: 0.100\n",
      "Episode: 1051, Reward: 220.0, avg loss: 0.05332, eps: 0.100\n",
      "Episode: 1052, Reward: 335.0, avg loss: 0.04412, eps: 0.100\n",
      "Episode: 1053, Reward: 295.0, avg loss: 0.03010, eps: 0.100\n",
      "Episode: 1054, Reward: 220.0, avg loss: 0.03470, eps: 0.100\n",
      "Episode: 1055, Reward: 170.0, avg loss: 0.04168, eps: 0.100\n",
      "Episode: 1056, Reward: 150.0, avg loss: 0.02868, eps: 0.100\n",
      "Episode: 1057, Reward: 190.0, avg loss: 0.02423, eps: 0.100\n",
      "Episode: 1058, Reward: 145.0, avg loss: 0.02024, eps: 0.100\n",
      "Episode: 1059, Reward: 145.0, avg loss: 0.02447, eps: 0.100\n",
      "Episode: 1060, Reward: 160.0, avg loss: 0.04038, eps: 0.100\n",
      "Episode: 1061, Reward: 400.0, avg loss: 0.04636, eps: 0.100\n",
      "Episode: 1062, Reward: 160.0, avg loss: 0.05510, eps: 0.100\n",
      "Episode: 1063, Reward: 160.0, avg loss: 0.05531, eps: 0.100\n",
      "Episode: 1064, Reward: 240.0, avg loss: 0.03002, eps: 0.100\n",
      "Episode: 1065, Reward: 720.0, avg loss: 0.05251, eps: 0.100\n",
      "Episode: 1066, Reward: 365.0, avg loss: 0.02841, eps: 0.100\n",
      "Episode: 1067, Reward: 110.0, avg loss: 0.02442, eps: 0.100\n",
      "Episode: 1068, Reward: 105.0, avg loss: 0.02636, eps: 0.100\n",
      "Episode: 1069, Reward: 125.0, avg loss: 0.01790, eps: 0.100\n",
      "Episode: 1070, Reward: 155.0, avg loss: 0.02182, eps: 0.100\n",
      "Episode: 1071, Reward: 255.0, avg loss: 0.02453, eps: 0.100\n",
      "Episode: 1072, Reward: 190.0, avg loss: 0.05508, eps: 0.100\n",
      "Episode: 1073, Reward: 170.0, avg loss: 0.02522, eps: 0.100\n",
      "Episode: 1074, Reward: 205.0, avg loss: 0.02222, eps: 0.100\n",
      "Episode: 1075, Reward: 90.0, avg loss: 0.01568, eps: 0.100\n",
      "Episode: 1076, Reward: 285.0, avg loss: 0.03536, eps: 0.100\n",
      "Episode: 1077, Reward: 60.0, avg loss: 0.01696, eps: 0.100\n",
      "Episode: 1078, Reward: 150.0, avg loss: 0.02624, eps: 0.100\n",
      "Episode: 1079, Reward: 120.0, avg loss: 0.02193, eps: 0.100\n",
      "Episode: 1080, Reward: 140.0, avg loss: 0.01865, eps: 0.100\n",
      "Episode: 1081, Reward: 370.0, avg loss: 0.03774, eps: 0.100\n",
      "Episode: 1082, Reward: 70.0, avg loss: 0.03387, eps: 0.100\n",
      "Episode: 1083, Reward: 240.0, avg loss: 0.04152, eps: 0.100\n",
      "Episode: 1084, Reward: 135.0, avg loss: 0.04400, eps: 0.100\n",
      "Episode: 1085, Reward: 215.0, avg loss: 0.01587, eps: 0.100\n",
      "Episode: 1086, Reward: 210.0, avg loss: 0.04020, eps: 0.100\n",
      "Episode: 1087, Reward: 160.0, avg loss: 0.02179, eps: 0.100\n",
      "Episode: 1088, Reward: 195.0, avg loss: 0.04847, eps: 0.100\n",
      "Episode: 1089, Reward: 425.0, avg loss: 0.04151, eps: 0.100\n",
      "Episode: 1090, Reward: 105.0, avg loss: 0.05670, eps: 0.100\n",
      "Episode: 1091, Reward: 235.0, avg loss: 0.01925, eps: 0.100\n",
      "Episode: 1092, Reward: 265.0, avg loss: 0.03707, eps: 0.100\n",
      "Episode: 1093, Reward: 145.0, avg loss: 0.03116, eps: 0.100\n",
      "Episode: 1094, Reward: 275.0, avg loss: 0.03278, eps: 0.100\n",
      "Episode: 1095, Reward: 430.0, avg loss: 0.03065, eps: 0.100\n",
      "Episode: 1096, Reward: 135.0, avg loss: 0.02259, eps: 0.100\n",
      "Episode: 1097, Reward: 305.0, avg loss: 0.02189, eps: 0.100\n",
      "Episode: 1098, Reward: 210.0, avg loss: 0.04044, eps: 0.100\n",
      "Episode: 1099, Reward: 380.0, avg loss: 0.05792, eps: 0.100\n",
      "Episode: 1100, Reward: 400.0, avg loss: 0.05283, eps: 0.100\n",
      "Episode: 1101, Reward: 185.0, avg loss: 0.03694, eps: 0.100\n",
      "Episode: 1102, Reward: 415.0, avg loss: 0.05148, eps: 0.100\n",
      "Episode: 1103, Reward: 435.0, avg loss: 0.02852, eps: 0.100\n",
      "Episode: 1104, Reward: 155.0, avg loss: 0.02780, eps: 0.100\n",
      "Episode: 1105, Reward: 140.0, avg loss: 0.02832, eps: 0.100\n",
      "Episode: 1106, Reward: 245.0, avg loss: 0.03375, eps: 0.100\n",
      "Episode: 1107, Reward: 175.0, avg loss: 0.03841, eps: 0.100\n",
      "Episode: 1108, Reward: 140.0, avg loss: 0.04900, eps: 0.100\n",
      "Episode: 1109, Reward: 285.0, avg loss: 0.03550, eps: 0.100\n",
      "Episode: 1110, Reward: 125.0, avg loss: 0.02665, eps: 0.100\n",
      "Episode: 1111, Reward: 245.0, avg loss: 0.04210, eps: 0.100\n",
      "Episode: 1112, Reward: 120.0, avg loss: 0.02875, eps: 0.100\n",
      "Episode: 1113, Reward: 485.0, avg loss: 0.05440, eps: 0.100\n",
      "Episode: 1114, Reward: 170.0, avg loss: 0.02794, eps: 0.100\n",
      "Episode: 1115, Reward: 100.0, avg loss: 0.02512, eps: 0.100\n",
      "Episode: 1116, Reward: 135.0, avg loss: 0.01737, eps: 0.100\n",
      "Episode: 1117, Reward: 180.0, avg loss: 0.03141, eps: 0.100\n",
      "Episode: 1118, Reward: 50.0, avg loss: 0.02288, eps: 0.100\n",
      "Episode: 1119, Reward: 170.0, avg loss: 0.02911, eps: 0.100\n",
      "Episode: 1120, Reward: 180.0, avg loss: 0.03409, eps: 0.100\n",
      "Episode: 1121, Reward: 15.0, avg loss: 0.02061, eps: 0.100\n",
      "Episode: 1122, Reward: 140.0, avg loss: 0.01072, eps: 0.100\n",
      "Episode: 1123, Reward: 215.0, avg loss: 0.01247, eps: 0.100\n",
      "Episode: 1124, Reward: 160.0, avg loss: 0.03144, eps: 0.100\n",
      "Episode: 1125, Reward: 210.0, avg loss: 0.04870, eps: 0.100\n",
      "Episode: 1126, Reward: 160.0, avg loss: 0.02156, eps: 0.100\n",
      "Episode: 1127, Reward: 45.0, avg loss: 0.02606, eps: 0.100\n",
      "Episode: 1128, Reward: 70.0, avg loss: 0.01206, eps: 0.100\n",
      "Episode: 1129, Reward: 135.0, avg loss: 0.00897, eps: 0.100\n",
      "Episode: 1130, Reward: 55.0, avg loss: 0.00903, eps: 0.100\n",
      "Episode: 1131, Reward: 265.0, avg loss: 0.02165, eps: 0.100\n",
      "Episode: 1132, Reward: 140.0, avg loss: 0.02068, eps: 0.100\n",
      "Episode: 1133, Reward: 205.0, avg loss: 0.02773, eps: 0.100\n",
      "Episode: 1134, Reward: 115.0, avg loss: 0.02296, eps: 0.100\n",
      "Episode: 1135, Reward: 75.0, avg loss: 0.01833, eps: 0.100\n",
      "Episode: 1136, Reward: 205.0, avg loss: 0.02911, eps: 0.100\n",
      "Episode: 1137, Reward: 290.0, avg loss: 0.04443, eps: 0.100\n",
      "Episode: 1138, Reward: 120.0, avg loss: 0.03983, eps: 0.100\n",
      "Episode: 1139, Reward: 125.0, avg loss: 0.03525, eps: 0.100\n",
      "Episode: 1140, Reward: 270.0, avg loss: 0.04304, eps: 0.100\n",
      "Episode: 1141, Reward: 145.0, avg loss: 0.02188, eps: 0.100\n",
      "Episode: 1142, Reward: 325.0, avg loss: 0.02848, eps: 0.100\n",
      "Episode: 1143, Reward: 240.0, avg loss: 0.04456, eps: 0.100\n",
      "Episode: 1144, Reward: 65.0, avg loss: 0.02252, eps: 0.100\n",
      "Episode: 1145, Reward: 495.0, avg loss: 0.09097, eps: 0.100\n",
      "Episode: 1146, Reward: 180.0, avg loss: 0.05933, eps: 0.100\n",
      "Episode: 1147, Reward: 375.0, avg loss: 0.04247, eps: 0.100\n",
      "Episode: 1148, Reward: 80.0, avg loss: 0.08164, eps: 0.100\n",
      "Episode: 1149, Reward: 45.0, avg loss: 0.03473, eps: 0.100\n",
      "Episode: 1150, Reward: 155.0, avg loss: 0.02902, eps: 0.100\n",
      "Episode: 1151, Reward: 105.0, avg loss: 0.03816, eps: 0.100\n",
      "Episode: 1152, Reward: 80.0, avg loss: 0.01478, eps: 0.100\n",
      "Episode: 1153, Reward: 120.0, avg loss: 0.02442, eps: 0.100\n",
      "Episode: 1154, Reward: 410.0, avg loss: 0.05110, eps: 0.100\n",
      "Episode: 1155, Reward: 180.0, avg loss: 0.04272, eps: 0.100\n",
      "Episode: 1156, Reward: 135.0, avg loss: 0.03141, eps: 0.100\n",
      "Episode: 1157, Reward: 345.0, avg loss: 0.04658, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1158, Reward: 240.0, avg loss: 0.01175, eps: 0.100\n",
      "Episode: 1159, Reward: 105.0, avg loss: 0.01452, eps: 0.100\n",
      "Episode: 1160, Reward: 520.0, avg loss: 0.05089, eps: 0.100\n",
      "Episode: 1161, Reward: 120.0, avg loss: 0.06136, eps: 0.100\n",
      "Episode: 1162, Reward: 210.0, avg loss: 0.03563, eps: 0.100\n",
      "Episode: 1163, Reward: 295.0, avg loss: 0.04714, eps: 0.100\n",
      "Episode: 1164, Reward: 320.0, avg loss: 0.05170, eps: 0.100\n",
      "Episode: 1165, Reward: 130.0, avg loss: 0.02609, eps: 0.100\n",
      "Episode: 1166, Reward: 255.0, avg loss: 0.05306, eps: 0.100\n",
      "Episode: 1167, Reward: 300.0, avg loss: 0.04571, eps: 0.100\n",
      "Episode: 1168, Reward: 335.0, avg loss: 0.05126, eps: 0.100\n",
      "Episode: 1169, Reward: 260.0, avg loss: 0.02412, eps: 0.100\n",
      "Episode: 1170, Reward: 95.0, avg loss: 0.00901, eps: 0.100\n",
      "Episode: 1171, Reward: 80.0, avg loss: 0.01740, eps: 0.100\n",
      "Episode: 1172, Reward: 215.0, avg loss: 0.02357, eps: 0.100\n",
      "Episode: 1173, Reward: 515.0, avg loss: 0.05987, eps: 0.100\n",
      "Episode: 1174, Reward: 125.0, avg loss: 0.03933, eps: 0.100\n",
      "Episode: 1175, Reward: 350.0, avg loss: 0.05080, eps: 0.100\n",
      "Episode: 1176, Reward: 755.0, avg loss: 0.07795, eps: 0.100\n",
      "Episode: 1177, Reward: 505.0, avg loss: 0.07360, eps: 0.100\n",
      "Episode: 1178, Reward: 140.0, avg loss: 0.03161, eps: 0.100\n",
      "Episode: 1179, Reward: 55.0, avg loss: 0.01851, eps: 0.100\n",
      "Episode: 1180, Reward: 235.0, avg loss: 0.03004, eps: 0.100\n",
      "Episode: 1181, Reward: 160.0, avg loss: 0.03820, eps: 0.100\n",
      "Episode: 1182, Reward: 285.0, avg loss: 0.02309, eps: 0.100\n",
      "Episode: 1183, Reward: 140.0, avg loss: 0.02933, eps: 0.100\n",
      "Episode: 1184, Reward: 655.0, avg loss: 0.05875, eps: 0.100\n",
      "Episode: 1185, Reward: 85.0, avg loss: 0.03098, eps: 0.100\n",
      "Episode: 1186, Reward: 50.0, avg loss: 0.00792, eps: 0.100\n",
      "Episode: 1187, Reward: 20.0, avg loss: 0.00766, eps: 0.100\n",
      "Episode: 1188, Reward: 215.0, avg loss: 0.03876, eps: 0.100\n",
      "Episode: 1189, Reward: 90.0, avg loss: 0.01872, eps: 0.100\n",
      "Episode: 1190, Reward: 115.0, avg loss: 0.01960, eps: 0.100\n",
      "Episode: 1191, Reward: 205.0, avg loss: 0.04842, eps: 0.100\n",
      "Episode: 1192, Reward: 270.0, avg loss: 0.05988, eps: 0.100\n",
      "Episode: 1193, Reward: 95.0, avg loss: 0.03481, eps: 0.100\n",
      "Episode: 1194, Reward: 210.0, avg loss: 0.01746, eps: 0.100\n",
      "Episode: 1195, Reward: 535.0, avg loss: 0.10289, eps: 0.100\n",
      "Episode: 1196, Reward: 30.0, avg loss: 0.06812, eps: 0.100\n",
      "Episode: 1197, Reward: 160.0, avg loss: 0.01819, eps: 0.100\n",
      "Episode: 1198, Reward: 90.0, avg loss: 0.01987, eps: 0.100\n",
      "Episode: 1199, Reward: 220.0, avg loss: 0.02899, eps: 0.100\n",
      "Episode: 1200, Reward: 145.0, avg loss: 0.02000, eps: 0.100\n",
      "Episode: 1201, Reward: 85.0, avg loss: 0.02250, eps: 0.100\n",
      "Episode: 1202, Reward: 410.0, avg loss: 0.04189, eps: 0.100\n",
      "Episode: 1203, Reward: 160.0, avg loss: 0.03616, eps: 0.100\n",
      "Episode: 1204, Reward: 245.0, avg loss: 0.01989, eps: 0.100\n",
      "Episode: 1205, Reward: 130.0, avg loss: 0.02701, eps: 0.100\n",
      "Episode: 1206, Reward: 260.0, avg loss: 0.03280, eps: 0.100\n",
      "Episode: 1207, Reward: 235.0, avg loss: 0.05441, eps: 0.100\n",
      "Episode: 1208, Reward: 135.0, avg loss: 0.03036, eps: 0.100\n",
      "Episode: 1209, Reward: 185.0, avg loss: 0.02260, eps: 0.100\n",
      "Episode: 1210, Reward: 230.0, avg loss: 0.02531, eps: 0.100\n",
      "Episode: 1211, Reward: 160.0, avg loss: 0.02829, eps: 0.100\n",
      "Episode: 1212, Reward: 155.0, avg loss: 0.02349, eps: 0.100\n",
      "Episode: 1213, Reward: 170.0, avg loss: 0.01722, eps: 0.100\n",
      "Episode: 1214, Reward: 250.0, avg loss: 0.03912, eps: 0.100\n",
      "Episode: 1215, Reward: 205.0, avg loss: 0.05084, eps: 0.100\n",
      "Episode: 1216, Reward: 110.0, avg loss: 0.03264, eps: 0.100\n",
      "Episode: 1217, Reward: 450.0, avg loss: 0.04301, eps: 0.100\n",
      "Episode: 1218, Reward: 150.0, avg loss: 0.04543, eps: 0.100\n",
      "Episode: 1219, Reward: 35.0, avg loss: 0.00376, eps: 0.100\n",
      "Episode: 1220, Reward: 60.0, avg loss: 0.01808, eps: 0.100\n",
      "Episode: 1221, Reward: 85.0, avg loss: 0.01985, eps: 0.100\n",
      "Episode: 1222, Reward: 175.0, avg loss: 0.02835, eps: 0.100\n",
      "Episode: 1223, Reward: 275.0, avg loss: 0.02873, eps: 0.100\n",
      "Episode: 1224, Reward: 215.0, avg loss: 0.02581, eps: 0.100\n",
      "Episode: 1225, Reward: 125.0, avg loss: 0.03080, eps: 0.100\n",
      "Episode: 1226, Reward: 265.0, avg loss: 0.02310, eps: 0.100\n",
      "Episode: 1227, Reward: 125.0, avg loss: 0.01390, eps: 0.100\n",
      "Episode: 1228, Reward: 275.0, avg loss: 0.06179, eps: 0.100\n",
      "Episode: 1229, Reward: 155.0, avg loss: 0.03902, eps: 0.100\n",
      "Episode: 1230, Reward: 165.0, avg loss: 0.01523, eps: 0.100\n",
      "Episode: 1231, Reward: 225.0, avg loss: 0.04018, eps: 0.100\n",
      "Episode: 1232, Reward: 245.0, avg loss: 0.02506, eps: 0.100\n",
      "Episode: 1233, Reward: 195.0, avg loss: 0.06935, eps: 0.100\n",
      "Episode: 1234, Reward: 245.0, avg loss: 0.04794, eps: 0.100\n",
      "Episode: 1235, Reward: 655.0, avg loss: 0.05402, eps: 0.100\n",
      "Episode: 1236, Reward: 280.0, avg loss: 0.05049, eps: 0.100\n",
      "Episode: 1237, Reward: 165.0, avg loss: 0.02896, eps: 0.100\n",
      "Episode: 1238, Reward: 105.0, avg loss: 0.03090, eps: 0.100\n",
      "Episode: 1239, Reward: 150.0, avg loss: 0.03001, eps: 0.100\n",
      "Episode: 1240, Reward: 395.0, avg loss: 0.03866, eps: 0.100\n",
      "Episode: 1241, Reward: 115.0, avg loss: 0.01579, eps: 0.100\n",
      "Episode: 1242, Reward: 35.0, avg loss: 0.00477, eps: 0.100\n",
      "Episode: 1243, Reward: 360.0, avg loss: 0.02008, eps: 0.100\n",
      "Episode: 1244, Reward: 80.0, avg loss: 0.00471, eps: 0.100\n",
      "Episode: 1245, Reward: 75.0, avg loss: 0.02431, eps: 0.100\n",
      "Episode: 1246, Reward: 370.0, avg loss: 0.04487, eps: 0.100\n",
      "Episode: 1247, Reward: 190.0, avg loss: 0.03373, eps: 0.100\n",
      "Episode: 1248, Reward: 175.0, avg loss: 0.02053, eps: 0.100\n",
      "Episode: 1249, Reward: 150.0, avg loss: 0.02030, eps: 0.100\n",
      "Episode: 1250, Reward: 195.0, avg loss: 0.02440, eps: 0.100\n",
      "Episode: 1251, Reward: 190.0, avg loss: 0.04605, eps: 0.100\n",
      "Episode: 1252, Reward: 220.0, avg loss: 0.02805, eps: 0.100\n",
      "Episode: 1253, Reward: 105.0, avg loss: 0.04218, eps: 0.100\n",
      "Episode: 1254, Reward: 160.0, avg loss: 0.03447, eps: 0.100\n",
      "Episode: 1255, Reward: 115.0, avg loss: 0.04395, eps: 0.100\n",
      "Episode: 1256, Reward: 255.0, avg loss: 0.03630, eps: 0.100\n",
      "Episode: 1257, Reward: 195.0, avg loss: 0.03073, eps: 0.100\n",
      "Episode: 1258, Reward: 130.0, avg loss: 0.03457, eps: 0.100\n",
      "Episode: 1259, Reward: 225.0, avg loss: 0.03220, eps: 0.100\n",
      "Episode: 1260, Reward: 140.0, avg loss: 0.01303, eps: 0.100\n",
      "Episode: 1261, Reward: 205.0, avg loss: 0.04185, eps: 0.100\n",
      "Episode: 1262, Reward: 200.0, avg loss: 0.03935, eps: 0.100\n",
      "Episode: 1263, Reward: 195.0, avg loss: 0.03777, eps: 0.100\n",
      "Episode: 1264, Reward: 165.0, avg loss: 0.06339, eps: 0.100\n",
      "Episode: 1265, Reward: 15.0, avg loss: 0.00296, eps: 0.100\n",
      "Episode: 1266, Reward: 195.0, avg loss: 0.02328, eps: 0.100\n",
      "Episode: 1267, Reward: 195.0, avg loss: 0.02459, eps: 0.100\n",
      "Episode: 1268, Reward: 215.0, avg loss: 0.01811, eps: 0.100\n",
      "Episode: 1269, Reward: 195.0, avg loss: 0.02281, eps: 0.100\n",
      "Episode: 1270, Reward: 385.0, avg loss: 0.04080, eps: 0.100\n",
      "Episode: 1271, Reward: 190.0, avg loss: 0.03722, eps: 0.100\n",
      "Episode: 1272, Reward: 125.0, avg loss: 0.01772, eps: 0.100\n",
      "Episode: 1273, Reward: 110.0, avg loss: 0.01760, eps: 0.100\n",
      "Episode: 1274, Reward: 220.0, avg loss: 0.03897, eps: 0.100\n",
      "Episode: 1275, Reward: 80.0, avg loss: 0.03095, eps: 0.100\n",
      "Episode: 1276, Reward: 110.0, avg loss: 0.01361, eps: 0.100\n",
      "Episode: 1277, Reward: 190.0, avg loss: 0.02403, eps: 0.100\n",
      "Episode: 1278, Reward: 175.0, avg loss: 0.01791, eps: 0.100\n",
      "Episode: 1279, Reward: 135.0, avg loss: 0.02484, eps: 0.100\n",
      "Episode: 1280, Reward: 120.0, avg loss: 0.01930, eps: 0.100\n",
      "Episode: 1281, Reward: 360.0, avg loss: 0.03089, eps: 0.100\n",
      "Episode: 1282, Reward: 175.0, avg loss: 0.03949, eps: 0.100\n",
      "Episode: 1283, Reward: 375.0, avg loss: 0.03833, eps: 0.100\n",
      "Episode: 1284, Reward: 220.0, avg loss: 0.04678, eps: 0.100\n",
      "Episode: 1285, Reward: 445.0, avg loss: 0.05567, eps: 0.100\n",
      "Episode: 1286, Reward: 200.0, avg loss: 0.02978, eps: 0.100\n",
      "Episode: 1287, Reward: 260.0, avg loss: 0.03659, eps: 0.100\n",
      "Episode: 1288, Reward: 205.0, avg loss: 0.03157, eps: 0.100\n",
      "Episode: 1289, Reward: 150.0, avg loss: 0.02563, eps: 0.100\n",
      "Episode: 1290, Reward: 150.0, avg loss: 0.01162, eps: 0.100\n",
      "Episode: 1291, Reward: 115.0, avg loss: 0.02951, eps: 0.100\n",
      "Episode: 1292, Reward: 65.0, avg loss: 0.01981, eps: 0.100\n",
      "Episode: 1293, Reward: 465.0, avg loss: 0.03643, eps: 0.100\n",
      "Episode: 1294, Reward: 190.0, avg loss: 0.03634, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1295, Reward: 210.0, avg loss: 0.01855, eps: 0.100\n",
      "Episode: 1296, Reward: 420.0, avg loss: 0.03197, eps: 0.100\n",
      "Episode: 1297, Reward: 175.0, avg loss: 0.02434, eps: 0.100\n",
      "Episode: 1298, Reward: 195.0, avg loss: 0.01966, eps: 0.100\n",
      "Episode: 1299, Reward: 210.0, avg loss: 0.03512, eps: 0.100\n",
      "Episode: 1300, Reward: 115.0, avg loss: 0.03131, eps: 0.100\n",
      "Episode: 1301, Reward: 175.0, avg loss: 0.02491, eps: 0.100\n",
      "Episode: 1302, Reward: 145.0, avg loss: 0.02238, eps: 0.100\n",
      "Episode: 1303, Reward: 75.0, avg loss: 0.02038, eps: 0.100\n",
      "Episode: 1304, Reward: 85.0, avg loss: 0.01562, eps: 0.100\n",
      "Episode: 1305, Reward: 170.0, avg loss: 0.02387, eps: 0.100\n",
      "Episode: 1306, Reward: 245.0, avg loss: 0.02689, eps: 0.100\n",
      "Episode: 1307, Reward: 125.0, avg loss: 0.04670, eps: 0.100\n",
      "Episode: 1308, Reward: 180.0, avg loss: 0.03196, eps: 0.100\n",
      "Episode: 1309, Reward: 290.0, avg loss: 0.02764, eps: 0.100\n",
      "Episode: 1310, Reward: 160.0, avg loss: 0.02227, eps: 0.100\n",
      "Episode: 1311, Reward: 185.0, avg loss: 0.02160, eps: 0.100\n",
      "Episode: 1312, Reward: 80.0, avg loss: 0.01751, eps: 0.100\n",
      "Episode: 1313, Reward: 130.0, avg loss: 0.02071, eps: 0.100\n",
      "Episode: 1314, Reward: 105.0, avg loss: 0.03631, eps: 0.100\n",
      "Episode: 1315, Reward: 55.0, avg loss: 0.01541, eps: 0.100\n",
      "Episode: 1316, Reward: 500.0, avg loss: 0.03448, eps: 0.100\n",
      "Episode: 1317, Reward: 350.0, avg loss: 0.06873, eps: 0.100\n",
      "Episode: 1318, Reward: 305.0, avg loss: 0.07581, eps: 0.100\n",
      "Episode: 1319, Reward: 135.0, avg loss: 0.02282, eps: 0.100\n",
      "Episode: 1320, Reward: 125.0, avg loss: 0.03610, eps: 0.100\n",
      "Episode: 1321, Reward: 265.0, avg loss: 0.02259, eps: 0.100\n",
      "Episode: 1322, Reward: 130.0, avg loss: 0.02446, eps: 0.100\n",
      "Episode: 1323, Reward: 235.0, avg loss: 0.02453, eps: 0.100\n",
      "Episode: 1324, Reward: 40.0, avg loss: 0.01518, eps: 0.100\n",
      "Episode: 1325, Reward: 210.0, avg loss: 0.03733, eps: 0.100\n",
      "Episode: 1326, Reward: 105.0, avg loss: 0.02325, eps: 0.100\n",
      "Episode: 1327, Reward: 125.0, avg loss: 0.02669, eps: 0.100\n",
      "Episode: 1328, Reward: 205.0, avg loss: 0.02631, eps: 0.100\n",
      "Episode: 1329, Reward: 195.0, avg loss: 0.01323, eps: 0.100\n",
      "Episode: 1330, Reward: 235.0, avg loss: 0.05271, eps: 0.100\n",
      "Episode: 1331, Reward: 410.0, avg loss: 0.07346, eps: 0.100\n",
      "Episode: 1332, Reward: 115.0, avg loss: 0.02287, eps: 0.100\n",
      "Episode: 1333, Reward: 200.0, avg loss: 0.02281, eps: 0.100\n",
      "Episode: 1334, Reward: 225.0, avg loss: 0.03949, eps: 0.100\n",
      "Episode: 1335, Reward: 250.0, avg loss: 0.04005, eps: 0.100\n",
      "Episode: 1336, Reward: 105.0, avg loss: 0.03372, eps: 0.100\n",
      "Episode: 1337, Reward: 40.0, avg loss: 0.02395, eps: 0.100\n",
      "Episode: 1338, Reward: 180.0, avg loss: 0.02481, eps: 0.100\n",
      "Episode: 1339, Reward: 170.0, avg loss: 0.03403, eps: 0.100\n",
      "Episode: 1340, Reward: 535.0, avg loss: 0.02858, eps: 0.100\n",
      "Episode: 1341, Reward: 305.0, avg loss: 0.11904, eps: 0.100\n",
      "Episode: 1342, Reward: 360.0, avg loss: 0.06387, eps: 0.100\n",
      "Episode: 1343, Reward: 220.0, avg loss: 0.03205, eps: 0.100\n",
      "Episode: 1344, Reward: 75.0, avg loss: 0.02891, eps: 0.100\n",
      "Episode: 1345, Reward: 140.0, avg loss: 0.01839, eps: 0.100\n",
      "Episode: 1346, Reward: 155.0, avg loss: 0.03987, eps: 0.100\n",
      "Episode: 1347, Reward: 225.0, avg loss: 0.05172, eps: 0.100\n",
      "Episode: 1348, Reward: 225.0, avg loss: 0.04333, eps: 0.100\n",
      "Episode: 1349, Reward: 265.0, avg loss: 0.03784, eps: 0.100\n",
      "Episode: 1350, Reward: 280.0, avg loss: 0.03237, eps: 0.100\n",
      "Episode: 1351, Reward: 175.0, avg loss: 0.03574, eps: 0.100\n",
      "Episode: 1352, Reward: 120.0, avg loss: 0.03703, eps: 0.100\n",
      "Episode: 1353, Reward: 50.0, avg loss: 0.00551, eps: 0.100\n",
      "Episode: 1354, Reward: 210.0, avg loss: 0.02355, eps: 0.100\n",
      "Episode: 1355, Reward: 115.0, avg loss: 0.02439, eps: 0.100\n",
      "Episode: 1356, Reward: 280.0, avg loss: 0.03068, eps: 0.100\n",
      "Episode: 1357, Reward: 125.0, avg loss: 0.04034, eps: 0.100\n",
      "Episode: 1358, Reward: 80.0, avg loss: 0.01122, eps: 0.100\n",
      "Episode: 1359, Reward: 115.0, avg loss: 0.01766, eps: 0.100\n",
      "Episode: 1360, Reward: 155.0, avg loss: 0.03736, eps: 0.100\n",
      "Episode: 1361, Reward: 245.0, avg loss: 0.06019, eps: 0.100\n",
      "Episode: 1362, Reward: 160.0, avg loss: 0.03072, eps: 0.100\n",
      "Episode: 1363, Reward: 135.0, avg loss: 0.04635, eps: 0.100\n",
      "Episode: 1364, Reward: 360.0, avg loss: 0.04588, eps: 0.100\n",
      "Episode: 1365, Reward: 235.0, avg loss: 0.06172, eps: 0.100\n",
      "Episode: 1366, Reward: 115.0, avg loss: 0.02409, eps: 0.100\n",
      "Episode: 1367, Reward: 215.0, avg loss: 0.02279, eps: 0.100\n",
      "Episode: 1368, Reward: 85.0, avg loss: 0.00889, eps: 0.100\n",
      "Episode: 1369, Reward: 140.0, avg loss: 0.01265, eps: 0.100\n",
      "Episode: 1370, Reward: 365.0, avg loss: 0.04656, eps: 0.100\n",
      "Episode: 1371, Reward: 330.0, avg loss: 0.06592, eps: 0.100\n",
      "Episode: 1372, Reward: 185.0, avg loss: 0.04130, eps: 0.100\n",
      "Episode: 1373, Reward: 110.0, avg loss: 0.05078, eps: 0.100\n",
      "Episode: 1374, Reward: 345.0, avg loss: 0.04898, eps: 0.100\n",
      "Episode: 1375, Reward: 140.0, avg loss: 0.02960, eps: 0.100\n",
      "Episode: 1376, Reward: 170.0, avg loss: 0.02669, eps: 0.100\n",
      "Episode: 1377, Reward: 145.0, avg loss: 0.04931, eps: 0.100\n",
      "Episode: 1378, Reward: 455.0, avg loss: 0.04062, eps: 0.100\n",
      "Episode: 1379, Reward: 325.0, avg loss: 0.06830, eps: 0.100\n",
      "Episode: 1380, Reward: 440.0, avg loss: 0.05822, eps: 0.100\n",
      "Episode: 1381, Reward: 130.0, avg loss: 0.04707, eps: 0.100\n",
      "Episode: 1382, Reward: 170.0, avg loss: 0.03820, eps: 0.100\n",
      "Episode: 1383, Reward: 75.0, avg loss: 0.02739, eps: 0.100\n",
      "Episode: 1384, Reward: 225.0, avg loss: 0.02638, eps: 0.100\n",
      "Episode: 1385, Reward: 175.0, avg loss: 0.04129, eps: 0.100\n",
      "Episode: 1386, Reward: 220.0, avg loss: 0.04140, eps: 0.100\n",
      "Episode: 1387, Reward: 315.0, avg loss: 0.03765, eps: 0.100\n",
      "Episode: 1388, Reward: 70.0, avg loss: 0.03308, eps: 0.100\n",
      "Episode: 1389, Reward: 245.0, avg loss: 0.03510, eps: 0.100\n",
      "Episode: 1390, Reward: 235.0, avg loss: 0.04462, eps: 0.100\n",
      "Episode: 1391, Reward: 360.0, avg loss: 0.03722, eps: 0.100\n",
      "Episode: 1392, Reward: 230.0, avg loss: 0.03547, eps: 0.100\n",
      "Episode: 1393, Reward: 235.0, avg loss: 0.06553, eps: 0.100\n",
      "Episode: 1394, Reward: 130.0, avg loss: 0.02879, eps: 0.100\n",
      "Episode: 1395, Reward: 270.0, avg loss: 0.02814, eps: 0.100\n",
      "Episode: 1396, Reward: 220.0, avg loss: 0.03405, eps: 0.100\n",
      "Episode: 1397, Reward: 335.0, avg loss: 0.02724, eps: 0.100\n",
      "Episode: 1398, Reward: 135.0, avg loss: 0.01494, eps: 0.100\n",
      "Episode: 1399, Reward: 220.0, avg loss: 0.03454, eps: 0.100\n",
      "Episode: 1400, Reward: 115.0, avg loss: 0.02230, eps: 0.100\n",
      "Episode: 1401, Reward: 105.0, avg loss: 0.02724, eps: 0.100\n",
      "Episode: 1402, Reward: 80.0, avg loss: 0.00805, eps: 0.100\n",
      "Episode: 1403, Reward: 270.0, avg loss: 0.02285, eps: 0.100\n",
      "Episode: 1404, Reward: 345.0, avg loss: 0.03950, eps: 0.100\n",
      "Episode: 1405, Reward: 165.0, avg loss: 0.07011, eps: 0.100\n",
      "Episode: 1406, Reward: 55.0, avg loss: 0.03793, eps: 0.100\n",
      "Episode: 1407, Reward: 215.0, avg loss: 0.03781, eps: 0.100\n",
      "Episode: 1408, Reward: 140.0, avg loss: 0.02367, eps: 0.100\n",
      "Episode: 1409, Reward: 165.0, avg loss: 0.03032, eps: 0.100\n",
      "Episode: 1410, Reward: 150.0, avg loss: 0.01960, eps: 0.100\n",
      "Episode: 1411, Reward: 210.0, avg loss: 0.04565, eps: 0.100\n",
      "Episode: 1412, Reward: 210.0, avg loss: 0.05317, eps: 0.100\n",
      "Episode: 1413, Reward: 90.0, avg loss: 0.03367, eps: 0.100\n",
      "Episode: 1414, Reward: 155.0, avg loss: 0.02684, eps: 0.100\n",
      "Episode: 1415, Reward: 455.0, avg loss: 1.82572, eps: 0.100\n",
      "Episode: 1416, Reward: 190.0, avg loss: 2.49409, eps: 0.100\n",
      "Episode: 1417, Reward: 455.0, avg loss: 2.24081, eps: 0.100\n",
      "Episode: 1418, Reward: 280.0, avg loss: 0.64887, eps: 0.100\n",
      "Episode: 1419, Reward: 200.0, avg loss: 1.88897, eps: 0.100\n",
      "Episode: 1420, Reward: 135.0, avg loss: 2.90582, eps: 0.100\n",
      "Episode: 1421, Reward: 125.0, avg loss: 0.38852, eps: 0.100\n",
      "Episode: 1422, Reward: 310.0, avg loss: 0.03564, eps: 0.100\n",
      "Episode: 1423, Reward: 290.0, avg loss: 0.17041, eps: 0.100\n",
      "Episode: 1424, Reward: 325.0, avg loss: 0.05234, eps: 0.100\n",
      "Episode: 1425, Reward: 355.0, avg loss: 0.89381, eps: 0.100\n",
      "Episode: 1426, Reward: 480.0, avg loss: 1.18823, eps: 0.100\n",
      "Episode: 1427, Reward: 100.0, avg loss: 0.01903, eps: 0.100\n",
      "Episode: 1428, Reward: 50.0, avg loss: 0.01721, eps: 0.100\n",
      "Episode: 1429, Reward: 40.0, avg loss: 0.32044, eps: 0.100\n",
      "Episode: 1430, Reward: 285.0, avg loss: 0.73778, eps: 0.100\n",
      "Episode: 1431, Reward: 205.0, avg loss: 0.04914, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1432, Reward: 290.0, avg loss: 0.45420, eps: 0.100\n",
      "Episode: 1433, Reward: 30.0, avg loss: 10.25178, eps: 0.100\n",
      "Episode: 1434, Reward: 95.0, avg loss: 0.68872, eps: 0.100\n",
      "Episode: 1435, Reward: 165.0, avg loss: 0.02547, eps: 0.100\n",
      "Episode: 1436, Reward: 110.0, avg loss: 0.03365, eps: 0.100\n",
      "Episode: 1437, Reward: 155.0, avg loss: 0.02992, eps: 0.100\n",
      "Episode: 1438, Reward: 140.0, avg loss: 0.09073, eps: 0.100\n",
      "Episode: 1439, Reward: 115.0, avg loss: 0.05640, eps: 0.100\n",
      "Episode: 1440, Reward: 90.0, avg loss: 0.00719, eps: 0.100\n",
      "Episode: 1441, Reward: 110.0, avg loss: 0.02389, eps: 0.100\n",
      "Episode: 1442, Reward: 130.0, avg loss: 0.43770, eps: 0.100\n",
      "Episode: 1443, Reward: 380.0, avg loss: 0.33302, eps: 0.100\n",
      "Episode: 1444, Reward: 450.0, avg loss: 0.07219, eps: 0.100\n",
      "Episode: 1445, Reward: 355.0, avg loss: 0.01947, eps: 0.100\n",
      "Episode: 1446, Reward: 435.0, avg loss: 0.06637, eps: 0.100\n",
      "Episode: 1447, Reward: 315.0, avg loss: 0.03902, eps: 0.100\n",
      "Episode: 1448, Reward: 165.0, avg loss: 0.03248, eps: 0.100\n",
      "Episode: 1449, Reward: 510.0, avg loss: 0.04326, eps: 0.100\n",
      "Episode: 1450, Reward: 35.0, avg loss: 0.02250, eps: 0.100\n",
      "Episode: 1451, Reward: 120.0, avg loss: 0.05032, eps: 0.100\n",
      "Episode: 1452, Reward: 145.0, avg loss: 0.03314, eps: 0.100\n",
      "Episode: 1453, Reward: 120.0, avg loss: 0.00997, eps: 0.100\n",
      "Episode: 1454, Reward: 400.0, avg loss: 0.04963, eps: 0.100\n",
      "Episode: 1455, Reward: 135.0, avg loss: 0.03988, eps: 0.100\n",
      "Episode: 1456, Reward: 150.0, avg loss: 0.02856, eps: 0.100\n",
      "Episode: 1457, Reward: 295.0, avg loss: 0.02371, eps: 0.100\n",
      "Episode: 1458, Reward: 270.0, avg loss: 0.02397, eps: 0.100\n",
      "Episode: 1459, Reward: 265.0, avg loss: 0.03089, eps: 0.100\n",
      "Episode: 1460, Reward: 345.0, avg loss: 0.02874, eps: 0.100\n",
      "Episode: 1461, Reward: 145.0, avg loss: 0.02180, eps: 0.100\n",
      "Episode: 1462, Reward: 390.0, avg loss: 0.01941, eps: 0.100\n",
      "Episode: 1463, Reward: 165.0, avg loss: 0.01040, eps: 0.100\n",
      "Episode: 1464, Reward: 155.0, avg loss: 0.02333, eps: 0.100\n",
      "Episode: 1465, Reward: 295.0, avg loss: 0.04513, eps: 0.100\n",
      "Episode: 1466, Reward: 335.0, avg loss: 0.03134, eps: 0.100\n",
      "Episode: 1467, Reward: 220.0, avg loss: 0.04676, eps: 0.100\n",
      "Episode: 1468, Reward: 120.0, avg loss: 0.02869, eps: 0.100\n",
      "Episode: 1469, Reward: 260.0, avg loss: 0.03139, eps: 0.100\n",
      "Episode: 1470, Reward: 460.0, avg loss: 0.03196, eps: 0.100\n",
      "Episode: 1471, Reward: 230.0, avg loss: 0.03427, eps: 0.100\n",
      "Episode: 1472, Reward: 135.0, avg loss: 0.02007, eps: 0.100\n",
      "Episode: 1473, Reward: 110.0, avg loss: 0.02681, eps: 0.100\n",
      "Episode: 1474, Reward: 100.0, avg loss: 0.02528, eps: 0.100\n",
      "Episode: 1475, Reward: 130.0, avg loss: 0.00977, eps: 0.100\n",
      "Episode: 1476, Reward: 95.0, avg loss: 0.02407, eps: 0.100\n",
      "Episode: 1477, Reward: 130.0, avg loss: 0.02783, eps: 0.100\n",
      "Episode: 1478, Reward: 250.0, avg loss: 0.05862, eps: 0.100\n",
      "Episode: 1479, Reward: 210.0, avg loss: 0.04007, eps: 0.100\n",
      "Episode: 1480, Reward: 225.0, avg loss: 0.02792, eps: 0.100\n",
      "Episode: 1481, Reward: 210.0, avg loss: 0.02013, eps: 0.100\n",
      "Episode: 1482, Reward: 210.0, avg loss: 0.03384, eps: 0.100\n",
      "Episode: 1483, Reward: 200.0, avg loss: 0.03878, eps: 0.100\n",
      "Episode: 1484, Reward: 155.0, avg loss: 0.03098, eps: 0.100\n",
      "Episode: 1485, Reward: 275.0, avg loss: 0.02859, eps: 0.100\n",
      "Episode: 1486, Reward: 255.0, avg loss: 0.03375, eps: 0.100\n",
      "Episode: 1487, Reward: 145.0, avg loss: 0.03718, eps: 0.100\n",
      "Episode: 1488, Reward: 245.0, avg loss: 0.05678, eps: 0.100\n",
      "Episode: 1489, Reward: 140.0, avg loss: 0.03996, eps: 0.100\n",
      "Episode: 1490, Reward: 110.0, avg loss: 0.03396, eps: 0.100\n",
      "Episode: 1491, Reward: 135.0, avg loss: 0.02969, eps: 0.100\n",
      "Episode: 1492, Reward: 235.0, avg loss: 0.02614, eps: 0.100\n",
      "Episode: 1493, Reward: 410.0, avg loss: 0.02942, eps: 0.100\n",
      "Episode: 1494, Reward: 305.0, avg loss: 0.04295, eps: 0.100\n",
      "Episode: 1495, Reward: 190.0, avg loss: 0.03748, eps: 0.100\n",
      "Episode: 1496, Reward: 55.0, avg loss: 0.02937, eps: 0.100\n",
      "Episode: 1497, Reward: 85.0, avg loss: 0.02638, eps: 0.100\n",
      "Episode: 1498, Reward: 25.0, avg loss: 0.02029, eps: 0.100\n",
      "Episode: 1499, Reward: 215.0, avg loss: 0.02061, eps: 0.100\n",
      "Episode: 1500, Reward: 185.0, avg loss: 0.02150, eps: 0.100\n",
      "Episode: 1501, Reward: 305.0, avg loss: 0.03494, eps: 0.100\n",
      "Episode: 1502, Reward: 80.0, avg loss: 0.01088, eps: 0.100\n",
      "Episode: 1503, Reward: 105.0, avg loss: 0.00976, eps: 0.100\n",
      "Episode: 1504, Reward: 165.0, avg loss: 0.01334, eps: 0.100\n",
      "Episode: 1505, Reward: 275.0, avg loss: 0.06228, eps: 0.100\n",
      "Episode: 1506, Reward: 350.0, avg loss: 0.05425, eps: 0.100\n",
      "Episode: 1507, Reward: 80.0, avg loss: 0.03045, eps: 0.100\n",
      "Episode: 1508, Reward: 135.0, avg loss: 0.01119, eps: 0.100\n",
      "Episode: 1509, Reward: 125.0, avg loss: 0.02061, eps: 0.100\n",
      "Episode: 1510, Reward: 75.0, avg loss: 0.02115, eps: 0.100\n",
      "Episode: 1511, Reward: 395.0, avg loss: 0.02527, eps: 0.100\n",
      "Episode: 1512, Reward: 225.0, avg loss: 0.07810, eps: 0.100\n",
      "Episode: 1513, Reward: 775.0, avg loss: 0.06118, eps: 0.100\n",
      "Episode: 1514, Reward: 710.0, avg loss: 0.04398, eps: 0.100\n",
      "Episode: 1515, Reward: 415.0, avg loss: 0.05051, eps: 0.100\n",
      "Episode: 1516, Reward: 215.0, avg loss: 0.03381, eps: 0.100\n",
      "Episode: 1517, Reward: 440.0, avg loss: 0.04286, eps: 0.100\n",
      "Episode: 1518, Reward: 345.0, avg loss: 0.02325, eps: 0.100\n",
      "Episode: 1519, Reward: 245.0, avg loss: 0.04252, eps: 0.100\n",
      "Episode: 1520, Reward: 205.0, avg loss: 0.01653, eps: 0.100\n",
      "Episode: 1521, Reward: 235.0, avg loss: 0.02726, eps: 0.100\n",
      "Episode: 1522, Reward: 155.0, avg loss: 0.03099, eps: 0.100\n",
      "Episode: 1523, Reward: 235.0, avg loss: 0.02645, eps: 0.100\n",
      "Episode: 1524, Reward: 155.0, avg loss: 0.03890, eps: 0.100\n",
      "Episode: 1525, Reward: 210.0, avg loss: 0.02007, eps: 0.100\n",
      "Episode: 1526, Reward: 210.0, avg loss: 0.02905, eps: 0.100\n",
      "Episode: 1527, Reward: 155.0, avg loss: 0.02618, eps: 0.100\n",
      "Episode: 1528, Reward: 410.0, avg loss: 0.04384, eps: 0.100\n",
      "Episode: 1529, Reward: 155.0, avg loss: 0.03646, eps: 0.100\n",
      "Episode: 1530, Reward: 460.0, avg loss: 0.05374, eps: 0.100\n",
      "Episode: 1531, Reward: 430.0, avg loss: 0.06441, eps: 0.100\n",
      "Episode: 1532, Reward: 285.0, avg loss: 0.03870, eps: 0.100\n",
      "Episode: 1533, Reward: 190.0, avg loss: 0.03855, eps: 0.100\n",
      "Episode: 1534, Reward: 125.0, avg loss: 0.03859, eps: 0.100\n",
      "Episode: 1535, Reward: 175.0, avg loss: 0.02030, eps: 0.100\n",
      "Episode: 1536, Reward: 240.0, avg loss: 0.02253, eps: 0.100\n",
      "Episode: 1537, Reward: 380.0, avg loss: 0.02587, eps: 0.100\n",
      "Episode: 1538, Reward: 215.0, avg loss: 0.07210, eps: 0.100\n",
      "Episode: 1539, Reward: 70.0, avg loss: 0.01199, eps: 0.100\n",
      "Episode: 1540, Reward: 190.0, avg loss: 0.03263, eps: 0.100\n",
      "Episode: 1541, Reward: 130.0, avg loss: 0.02240, eps: 0.100\n",
      "Episode: 1542, Reward: 175.0, avg loss: 0.03192, eps: 0.100\n",
      "Episode: 1543, Reward: 295.0, avg loss: 0.02691, eps: 0.100\n",
      "Episode: 1544, Reward: 120.0, avg loss: 0.03240, eps: 0.100\n",
      "Episode: 1545, Reward: 580.0, avg loss: 0.02783, eps: 0.100\n",
      "Episode: 1546, Reward: 175.0, avg loss: 0.01981, eps: 0.100\n",
      "Episode: 1547, Reward: 515.0, avg loss: 0.06573, eps: 0.100\n",
      "Episode: 1548, Reward: 120.0, avg loss: 0.05043, eps: 0.100\n",
      "Episode: 1549, Reward: 155.0, avg loss: 0.02426, eps: 0.100\n",
      "Episode: 1550, Reward: 130.0, avg loss: 0.02218, eps: 0.100\n",
      "Episode: 1551, Reward: 265.0, avg loss: 0.03515, eps: 0.100\n",
      "Episode: 1552, Reward: 135.0, avg loss: 0.04384, eps: 0.100\n",
      "Episode: 1553, Reward: 315.0, avg loss: 0.05482, eps: 0.100\n",
      "Episode: 1554, Reward: 255.0, avg loss: 0.04452, eps: 0.100\n",
      "Episode: 1555, Reward: 230.0, avg loss: 0.03684, eps: 0.100\n",
      "Episode: 1556, Reward: 335.0, avg loss: 0.04302, eps: 0.100\n",
      "Episode: 1557, Reward: 190.0, avg loss: 0.02688, eps: 0.100\n",
      "Episode: 1558, Reward: 190.0, avg loss: 0.03488, eps: 0.100\n",
      "Episode: 1559, Reward: 320.0, avg loss: 0.02180, eps: 0.100\n",
      "Episode: 1560, Reward: 75.0, avg loss: 0.03452, eps: 0.100\n",
      "Episode: 1561, Reward: 185.0, avg loss: 0.03359, eps: 0.100\n",
      "Episode: 1562, Reward: 335.0, avg loss: 0.02494, eps: 0.100\n",
      "Episode: 1563, Reward: 215.0, avg loss: 0.03415, eps: 0.100\n",
      "Episode: 1564, Reward: 305.0, avg loss: 0.05292, eps: 0.100\n",
      "Episode: 1565, Reward: 205.0, avg loss: 0.01778, eps: 0.100\n",
      "Episode: 1566, Reward: 80.0, avg loss: 0.00975, eps: 0.100\n",
      "Episode: 1567, Reward: 170.0, avg loss: 0.04323, eps: 0.100\n",
      "Episode: 1568, Reward: 210.0, avg loss: 0.03855, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1569, Reward: 150.0, avg loss: 0.02489, eps: 0.100\n",
      "Episode: 1570, Reward: 255.0, avg loss: 0.03447, eps: 0.100\n",
      "Episode: 1571, Reward: 130.0, avg loss: 0.02231, eps: 0.100\n",
      "Episode: 1572, Reward: 105.0, avg loss: 0.02034, eps: 0.100\n",
      "Episode: 1573, Reward: 170.0, avg loss: 0.01705, eps: 0.100\n",
      "Episode: 1574, Reward: 95.0, avg loss: 0.01084, eps: 0.100\n",
      "Episode: 1575, Reward: 330.0, avg loss: 0.03010, eps: 0.100\n",
      "Episode: 1576, Reward: 335.0, avg loss: 0.03188, eps: 0.100\n",
      "Episode: 1577, Reward: 325.0, avg loss: 0.02485, eps: 0.100\n",
      "Episode: 1578, Reward: 160.0, avg loss: 0.02567, eps: 0.100\n",
      "Episode: 1579, Reward: 150.0, avg loss: 0.01534, eps: 0.100\n",
      "Episode: 1580, Reward: 135.0, avg loss: 0.02186, eps: 0.100\n",
      "Episode: 1581, Reward: 160.0, avg loss: 0.02353, eps: 0.100\n",
      "Episode: 1582, Reward: 110.0, avg loss: 0.02254, eps: 0.100\n",
      "Episode: 1583, Reward: 285.0, avg loss: 0.02125, eps: 0.100\n",
      "Episode: 1584, Reward: 175.0, avg loss: 0.02764, eps: 0.100\n",
      "Episode: 1585, Reward: 195.0, avg loss: 0.03472, eps: 0.100\n",
      "Episode: 1586, Reward: 225.0, avg loss: 0.02634, eps: 0.100\n",
      "Episode: 1587, Reward: 130.0, avg loss: 0.02037, eps: 0.100\n",
      "Episode: 1588, Reward: 285.0, avg loss: 0.04282, eps: 0.100\n",
      "Episode: 1589, Reward: 105.0, avg loss: 0.06796, eps: 0.100\n",
      "Episode: 1590, Reward: 195.0, avg loss: 0.03992, eps: 0.100\n",
      "Episode: 1591, Reward: 650.0, avg loss: 0.05004, eps: 0.100\n",
      "Episode: 1592, Reward: 245.0, avg loss: 0.01729, eps: 0.100\n",
      "Episode: 1593, Reward: 180.0, avg loss: 0.03288, eps: 0.100\n",
      "Episode: 1594, Reward: 105.0, avg loss: 0.02135, eps: 0.100\n",
      "Episode: 1595, Reward: 335.0, avg loss: 0.03490, eps: 0.100\n",
      "Episode: 1596, Reward: 105.0, avg loss: 0.01636, eps: 0.100\n",
      "Episode: 1597, Reward: 175.0, avg loss: 0.03801, eps: 0.100\n",
      "Episode: 1598, Reward: 145.0, avg loss: 0.01809, eps: 0.100\n",
      "Episode: 1599, Reward: 180.0, avg loss: 0.03531, eps: 0.100\n",
      "Episode: 1600, Reward: 205.0, avg loss: 0.03891, eps: 0.100\n",
      "Episode: 1601, Reward: 85.0, avg loss: 0.04035, eps: 0.100\n",
      "Episode: 1602, Reward: 30.0, avg loss: 0.03552, eps: 0.100\n",
      "Episode: 1603, Reward: 185.0, avg loss: 0.01965, eps: 0.100\n",
      "Episode: 1604, Reward: 35.0, avg loss: 0.01560, eps: 0.100\n",
      "Episode: 1605, Reward: 175.0, avg loss: 0.01702, eps: 0.100\n",
      "Episode: 1606, Reward: 225.0, avg loss: 0.03010, eps: 0.100\n",
      "Episode: 1607, Reward: 125.0, avg loss: 0.01251, eps: 0.100\n",
      "Episode: 1608, Reward: 155.0, avg loss: 0.02622, eps: 0.100\n",
      "Episode: 1609, Reward: 390.0, avg loss: 0.03249, eps: 0.100\n",
      "Episode: 1610, Reward: 210.0, avg loss: 0.04183, eps: 0.100\n",
      "Episode: 1611, Reward: 85.0, avg loss: 0.02383, eps: 0.100\n",
      "Episode: 1612, Reward: 10.0, avg loss: 0.00595, eps: 0.100\n",
      "Episode: 1613, Reward: 185.0, avg loss: 0.00888, eps: 0.100\n",
      "Episode: 1614, Reward: 140.0, avg loss: 0.02261, eps: 0.100\n",
      "Episode: 1615, Reward: 295.0, avg loss: 0.02151, eps: 0.100\n",
      "Episode: 1616, Reward: 180.0, avg loss: 0.03372, eps: 0.100\n",
      "Episode: 1617, Reward: 405.0, avg loss: 0.01968, eps: 0.100\n",
      "Episode: 1618, Reward: 295.0, avg loss: 0.03856, eps: 0.100\n",
      "Episode: 1619, Reward: 430.0, avg loss: 0.04324, eps: 0.100\n",
      "Episode: 1620, Reward: 200.0, avg loss: 0.03952, eps: 0.100\n",
      "Episode: 1621, Reward: 10.0, avg loss: 0.02104, eps: 0.100\n",
      "Episode: 1622, Reward: 125.0, avg loss: 0.01764, eps: 0.100\n",
      "Episode: 1623, Reward: 500.0, avg loss: 0.04367, eps: 0.100\n",
      "Episode: 1624, Reward: 265.0, avg loss: 0.03186, eps: 0.100\n",
      "Episode: 1625, Reward: 160.0, avg loss: 0.02824, eps: 0.100\n",
      "Episode: 1626, Reward: 80.0, avg loss: 0.03375, eps: 0.100\n",
      "Episode: 1627, Reward: 50.0, avg loss: 0.02650, eps: 0.100\n",
      "Episode: 1628, Reward: 145.0, avg loss: 0.03739, eps: 0.100\n",
      "Episode: 1629, Reward: 215.0, avg loss: 0.04597, eps: 0.100\n",
      "Episode: 1630, Reward: 260.0, avg loss: 0.02319, eps: 0.100\n",
      "Episode: 1631, Reward: 195.0, avg loss: 0.01690, eps: 0.100\n",
      "Episode: 1632, Reward: 260.0, avg loss: 0.02686, eps: 0.100\n",
      "Episode: 1633, Reward: 450.0, avg loss: 0.01989, eps: 0.100\n",
      "Episode: 1634, Reward: 580.0, avg loss: 0.06164, eps: 0.100\n",
      "Episode: 1635, Reward: 120.0, avg loss: 0.02140, eps: 0.100\n",
      "Episode: 1636, Reward: 475.0, avg loss: 0.06443, eps: 0.100\n",
      "Episode: 1637, Reward: 235.0, avg loss: 0.04317, eps: 0.100\n",
      "Episode: 1638, Reward: 140.0, avg loss: 0.02983, eps: 0.100\n",
      "Episode: 1639, Reward: 250.0, avg loss: 0.04666, eps: 0.100\n",
      "Episode: 1640, Reward: 135.0, avg loss: 0.02869, eps: 0.100\n",
      "Episode: 1641, Reward: 650.0, avg loss: 0.05484, eps: 0.100\n",
      "Episode: 1642, Reward: 215.0, avg loss: 0.05537, eps: 0.100\n",
      "Episode: 1643, Reward: 460.0, avg loss: 0.03864, eps: 0.100\n",
      "Episode: 1644, Reward: 315.0, avg loss: 0.03884, eps: 0.100\n",
      "Episode: 1645, Reward: 140.0, avg loss: 0.04303, eps: 0.100\n",
      "Episode: 1646, Reward: 200.0, avg loss: 0.02530, eps: 0.100\n",
      "Episode: 1647, Reward: 265.0, avg loss: 0.03608, eps: 0.100\n",
      "Episode: 1648, Reward: 40.0, avg loss: 0.02022, eps: 0.100\n",
      "Episode: 1649, Reward: 300.0, avg loss: 0.02847, eps: 0.100\n",
      "Episode: 1650, Reward: 50.0, avg loss: 0.03073, eps: 0.100\n",
      "Episode: 1651, Reward: 260.0, avg loss: 0.04036, eps: 0.100\n",
      "Episode: 1652, Reward: 170.0, avg loss: 0.01728, eps: 0.100\n",
      "Episode: 1653, Reward: 50.0, avg loss: 0.00608, eps: 0.100\n",
      "Episode: 1654, Reward: 195.0, avg loss: 0.01376, eps: 0.100\n",
      "Episode: 1655, Reward: 195.0, avg loss: 0.02666, eps: 0.100\n",
      "Episode: 1656, Reward: 170.0, avg loss: 0.02227, eps: 0.100\n",
      "Episode: 1657, Reward: 65.0, avg loss: 0.02776, eps: 0.100\n",
      "Episode: 1658, Reward: 190.0, avg loss: 0.02585, eps: 0.100\n",
      "Episode: 1659, Reward: 300.0, avg loss: 0.03517, eps: 0.100\n",
      "Episode: 1660, Reward: 115.0, avg loss: 0.02232, eps: 0.100\n",
      "Episode: 1661, Reward: 75.0, avg loss: 0.04069, eps: 0.100\n",
      "Episode: 1662, Reward: 160.0, avg loss: 0.01977, eps: 0.100\n",
      "Episode: 1663, Reward: 225.0, avg loss: 0.04371, eps: 0.100\n",
      "Episode: 1664, Reward: 260.0, avg loss: 0.03105, eps: 0.100\n",
      "Episode: 1665, Reward: 150.0, avg loss: 0.02496, eps: 0.100\n",
      "Episode: 1666, Reward: 265.0, avg loss: 0.03878, eps: 0.100\n",
      "Episode: 1667, Reward: 245.0, avg loss: 0.03652, eps: 0.100\n",
      "Episode: 1668, Reward: 95.0, avg loss: 0.02855, eps: 0.100\n",
      "Episode: 1669, Reward: 70.0, avg loss: 0.02328, eps: 0.100\n",
      "Episode: 1670, Reward: 215.0, avg loss: 0.01962, eps: 0.100\n",
      "Episode: 1671, Reward: 275.0, avg loss: 0.06343, eps: 0.100\n",
      "Episode: 1672, Reward: 110.0, avg loss: 0.03785, eps: 0.100\n",
      "Episode: 1673, Reward: 75.0, avg loss: 0.01569, eps: 0.100\n",
      "Episode: 1674, Reward: 190.0, avg loss: 0.03703, eps: 0.100\n",
      "Episode: 1675, Reward: 140.0, avg loss: 0.03606, eps: 0.100\n",
      "Episode: 1676, Reward: 155.0, avg loss: 0.03843, eps: 0.100\n",
      "Episode: 1677, Reward: 150.0, avg loss: 0.03082, eps: 0.100\n",
      "Episode: 1678, Reward: 145.0, avg loss: 0.02776, eps: 0.100\n",
      "Episode: 1679, Reward: 515.0, avg loss: 0.02518, eps: 0.100\n",
      "Episode: 1680, Reward: 180.0, avg loss: 0.08874, eps: 0.100\n",
      "Episode: 1681, Reward: 120.0, avg loss: 0.04089, eps: 0.100\n",
      "Episode: 1682, Reward: 300.0, avg loss: 0.02833, eps: 0.100\n",
      "Episode: 1683, Reward: 75.0, avg loss: 0.00920, eps: 0.100\n",
      "Episode: 1684, Reward: 80.0, avg loss: 0.02511, eps: 0.100\n",
      "Episode: 1685, Reward: 445.0, avg loss: 0.05065, eps: 0.100\n",
      "Episode: 1686, Reward: 105.0, avg loss: 0.01706, eps: 0.100\n",
      "Episode: 1687, Reward: 145.0, avg loss: 0.02243, eps: 0.100\n",
      "Episode: 1688, Reward: 570.0, avg loss: 0.10482, eps: 0.100\n",
      "Episode: 1689, Reward: 305.0, avg loss: 0.04697, eps: 0.100\n",
      "Episode: 1690, Reward: 260.0, avg loss: 0.03988, eps: 0.100\n",
      "Episode: 1691, Reward: 50.0, avg loss: 0.03258, eps: 0.100\n",
      "Episode: 1692, Reward: 110.0, avg loss: 0.01367, eps: 0.100\n",
      "Episode: 1693, Reward: 110.0, avg loss: 0.02304, eps: 0.100\n",
      "Episode: 1694, Reward: 150.0, avg loss: 0.04264, eps: 0.100\n",
      "Episode: 1695, Reward: 525.0, avg loss: 0.07856, eps: 0.100\n",
      "Episode: 1696, Reward: 120.0, avg loss: 0.03848, eps: 0.100\n",
      "Episode: 1697, Reward: 480.0, avg loss: 0.03328, eps: 0.100\n",
      "Episode: 1698, Reward: 210.0, avg loss: 0.04686, eps: 0.100\n",
      "Episode: 1699, Reward: 220.0, avg loss: 0.02571, eps: 0.100\n",
      "Episode: 1700, Reward: 365.0, avg loss: 0.04334, eps: 0.100\n",
      "Episode: 1701, Reward: 445.0, avg loss: 0.06273, eps: 0.100\n",
      "Episode: 1702, Reward: 390.0, avg loss: 0.03193, eps: 0.100\n",
      "Episode: 1703, Reward: 500.0, avg loss: 0.05514, eps: 0.100\n",
      "Episode: 1704, Reward: 50.0, avg loss: 0.01949, eps: 0.100\n",
      "Episode: 1705, Reward: 185.0, avg loss: 0.02629, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1706, Reward: 155.0, avg loss: 0.04241, eps: 0.100\n",
      "Episode: 1707, Reward: 265.0, avg loss: 0.06491, eps: 0.100\n",
      "Episode: 1708, Reward: 230.0, avg loss: 0.04623, eps: 0.100\n",
      "Episode: 1709, Reward: 250.0, avg loss: 0.05944, eps: 0.100\n",
      "Episode: 1710, Reward: 40.0, avg loss: 0.00941, eps: 0.100\n",
      "Episode: 1711, Reward: 255.0, avg loss: 0.01660, eps: 0.100\n",
      "Episode: 1712, Reward: 230.0, avg loss: 0.03518, eps: 0.100\n",
      "Episode: 1713, Reward: 420.0, avg loss: 0.08523, eps: 0.100\n",
      "Episode: 1714, Reward: 445.0, avg loss: 0.09465, eps: 0.100\n",
      "Episode: 1715, Reward: 210.0, avg loss: 0.02046, eps: 0.100\n",
      "Episode: 1716, Reward: 525.0, avg loss: 0.02811, eps: 0.100\n",
      "Episode: 1717, Reward: 165.0, avg loss: 0.01975, eps: 0.100\n",
      "Episode: 1718, Reward: 170.0, avg loss: 0.01668, eps: 0.100\n",
      "Episode: 1719, Reward: 460.0, avg loss: 0.05703, eps: 0.100\n",
      "Episode: 1720, Reward: 75.0, avg loss: 0.03273, eps: 0.100\n",
      "Episode: 1721, Reward: 175.0, avg loss: 0.04149, eps: 0.100\n",
      "Episode: 1722, Reward: 110.0, avg loss: 0.04585, eps: 0.100\n",
      "Episode: 1723, Reward: 110.0, avg loss: 0.03399, eps: 0.100\n",
      "Episode: 1724, Reward: 180.0, avg loss: 0.04111, eps: 0.100\n",
      "Episode: 1725, Reward: 185.0, avg loss: 0.04720, eps: 0.100\n",
      "Episode: 1726, Reward: 280.0, avg loss: 0.02504, eps: 0.100\n",
      "Episode: 1727, Reward: 115.0, avg loss: 0.03736, eps: 0.100\n",
      "Episode: 1728, Reward: 190.0, avg loss: 0.01934, eps: 0.100\n",
      "Episode: 1729, Reward: 15.0, avg loss: 0.02279, eps: 0.100\n",
      "Episode: 1730, Reward: 285.0, avg loss: 0.03008, eps: 0.100\n",
      "Episode: 1731, Reward: 345.0, avg loss: 0.05851, eps: 0.100\n",
      "Episode: 1732, Reward: 480.0, avg loss: 0.08867, eps: 0.100\n",
      "Episode: 1733, Reward: 150.0, avg loss: 0.04397, eps: 0.100\n",
      "Episode: 1734, Reward: 370.0, avg loss: 0.10457, eps: 0.100\n",
      "Episode: 1735, Reward: 220.0, avg loss: 0.07000, eps: 0.100\n",
      "Episode: 1736, Reward: 220.0, avg loss: 0.02699, eps: 0.100\n",
      "Episode: 1737, Reward: 270.0, avg loss: 0.01822, eps: 0.100\n",
      "Episode: 1738, Reward: 280.0, avg loss: 0.02496, eps: 0.100\n",
      "Episode: 1739, Reward: 260.0, avg loss: 0.02956, eps: 0.100\n",
      "Episode: 1740, Reward: 130.0, avg loss: 0.02617, eps: 0.100\n",
      "Episode: 1741, Reward: 535.0, avg loss: 0.02983, eps: 0.100\n",
      "Episode: 1742, Reward: 70.0, avg loss: 0.01698, eps: 0.100\n",
      "Episode: 1743, Reward: 100.0, avg loss: 0.01689, eps: 0.100\n",
      "Episode: 1744, Reward: 380.0, avg loss: 0.04106, eps: 0.100\n",
      "Episode: 1745, Reward: 210.0, avg loss: 0.02425, eps: 0.100\n",
      "Episode: 1746, Reward: 170.0, avg loss: 0.02886, eps: 0.100\n",
      "Episode: 1747, Reward: 160.0, avg loss: 0.02670, eps: 0.100\n",
      "Episode: 1748, Reward: 230.0, avg loss: 0.05694, eps: 0.100\n",
      "Episode: 1749, Reward: 475.0, avg loss: 0.04641, eps: 0.100\n",
      "Episode: 1750, Reward: 195.0, avg loss: 0.04039, eps: 0.100\n",
      "Episode: 1751, Reward: 255.0, avg loss: 0.02746, eps: 0.100\n",
      "Episode: 1752, Reward: 290.0, avg loss: 0.05978, eps: 0.100\n",
      "Episode: 1753, Reward: 250.0, avg loss: 0.05436, eps: 0.100\n",
      "Episode: 1754, Reward: 130.0, avg loss: 0.05051, eps: 0.100\n",
      "Episode: 1755, Reward: 210.0, avg loss: 0.02203, eps: 0.100\n",
      "Episode: 1756, Reward: 190.0, avg loss: 0.02924, eps: 0.100\n",
      "Episode: 1757, Reward: 65.0, avg loss: 0.02496, eps: 0.100\n",
      "Episode: 1758, Reward: 225.0, avg loss: 0.02713, eps: 0.100\n",
      "Episode: 1759, Reward: 115.0, avg loss: 0.01684, eps: 0.100\n",
      "Episode: 1760, Reward: 45.0, avg loss: 0.00690, eps: 0.100\n",
      "Episode: 1761, Reward: 315.0, avg loss: 0.02415, eps: 0.100\n",
      "Episode: 1762, Reward: 125.0, avg loss: 0.02826, eps: 0.100\n",
      "Episode: 1763, Reward: 335.0, avg loss: 0.02458, eps: 0.100\n",
      "Episode: 1764, Reward: 235.0, avg loss: 0.02760, eps: 0.100\n",
      "Episode: 1765, Reward: 190.0, avg loss: 0.02694, eps: 0.100\n",
      "Episode: 1766, Reward: 500.0, avg loss: 0.02973, eps: 0.100\n",
      "Episode: 1767, Reward: 305.0, avg loss: 0.04095, eps: 0.100\n",
      "Episode: 1768, Reward: 235.0, avg loss: 0.05099, eps: 0.100\n",
      "Episode: 1769, Reward: 195.0, avg loss: 0.02426, eps: 0.100\n",
      "Episode: 1770, Reward: 325.0, avg loss: 0.03449, eps: 0.100\n",
      "Episode: 1771, Reward: 250.0, avg loss: 0.04028, eps: 0.100\n",
      "Episode: 1772, Reward: 130.0, avg loss: 0.03012, eps: 0.100\n",
      "Episode: 1773, Reward: 235.0, avg loss: 0.02786, eps: 0.100\n",
      "Episode: 1774, Reward: 85.0, avg loss: 0.02893, eps: 0.100\n",
      "Episode: 1775, Reward: 195.0, avg loss: 0.02822, eps: 0.100\n",
      "Episode: 1776, Reward: 190.0, avg loss: 0.03814, eps: 0.100\n",
      "Episode: 1777, Reward: 255.0, avg loss: 0.02105, eps: 0.100\n",
      "Episode: 1778, Reward: 105.0, avg loss: 0.02576, eps: 0.100\n",
      "Episode: 1779, Reward: 110.0, avg loss: 0.03140, eps: 0.100\n",
      "Episode: 1780, Reward: 50.0, avg loss: 0.01689, eps: 0.100\n",
      "Episode: 1781, Reward: 110.0, avg loss: 0.02347, eps: 0.100\n",
      "Episode: 1782, Reward: 375.0, avg loss: 0.03788, eps: 0.100\n",
      "Episode: 1783, Reward: 525.0, avg loss: 0.06526, eps: 0.100\n",
      "Episode: 1784, Reward: 110.0, avg loss: 0.04605, eps: 0.100\n",
      "Episode: 1785, Reward: 410.0, avg loss: 0.02472, eps: 0.100\n",
      "Episode: 1786, Reward: 205.0, avg loss: 0.06866, eps: 0.100\n",
      "Episode: 1787, Reward: 180.0, avg loss: 0.03655, eps: 0.100\n",
      "Episode: 1788, Reward: 125.0, avg loss: 0.03149, eps: 0.100\n",
      "Episode: 1789, Reward: 305.0, avg loss: 0.03654, eps: 0.100\n",
      "Episode: 1790, Reward: 160.0, avg loss: 0.04097, eps: 0.100\n",
      "Episode: 1791, Reward: 150.0, avg loss: 0.02021, eps: 0.100\n",
      "Episode: 1792, Reward: 75.0, avg loss: 0.01019, eps: 0.100\n",
      "Episode: 1793, Reward: 90.0, avg loss: 0.00953, eps: 0.100\n",
      "Episode: 1794, Reward: 165.0, avg loss: 0.03173, eps: 0.100\n",
      "Episode: 1795, Reward: 135.0, avg loss: 0.02491, eps: 0.100\n",
      "Episode: 1796, Reward: 235.0, avg loss: 0.01679, eps: 0.100\n",
      "Episode: 1797, Reward: 440.0, avg loss: 0.07985, eps: 0.100\n",
      "Episode: 1798, Reward: 155.0, avg loss: 0.03103, eps: 0.100\n",
      "Episode: 1799, Reward: 145.0, avg loss: 0.02261, eps: 0.100\n",
      "Episode: 1800, Reward: 50.0, avg loss: 0.02076, eps: 0.100\n",
      "Episode: 1801, Reward: 50.0, avg loss: 0.02012, eps: 0.100\n",
      "Episode: 1802, Reward: 75.0, avg loss: 0.02440, eps: 0.100\n",
      "Episode: 1803, Reward: 315.0, avg loss: 0.02858, eps: 0.100\n",
      "Episode: 1804, Reward: 615.0, avg loss: 0.08507, eps: 0.100\n",
      "Episode: 1805, Reward: 235.0, avg loss: 0.02282, eps: 0.100\n",
      "Episode: 1806, Reward: 130.0, avg loss: 0.01966, eps: 0.100\n",
      "Episode: 1807, Reward: 365.0, avg loss: 0.06562, eps: 0.100\n",
      "Episode: 1808, Reward: 280.0, avg loss: 0.04831, eps: 0.100\n",
      "Episode: 1809, Reward: 70.0, avg loss: 0.01272, eps: 0.100\n",
      "Episode: 1810, Reward: 75.0, avg loss: 0.01360, eps: 0.100\n",
      "Episode: 1811, Reward: 105.0, avg loss: 0.01284, eps: 0.100\n",
      "Episode: 1812, Reward: 315.0, avg loss: 0.02910, eps: 0.100\n",
      "Episode: 1813, Reward: 210.0, avg loss: 0.02956, eps: 0.100\n",
      "Episode: 1814, Reward: 150.0, avg loss: 0.01956, eps: 0.100\n",
      "Episode: 1815, Reward: 250.0, avg loss: 0.08296, eps: 0.100\n",
      "Episode: 1816, Reward: 780.0, avg loss: 0.05484, eps: 0.100\n",
      "Episode: 1817, Reward: 335.0, avg loss: 0.05461, eps: 0.100\n",
      "Episode: 1818, Reward: 10.0, avg loss: 0.02072, eps: 0.100\n",
      "Episode: 1819, Reward: 190.0, avg loss: 0.01827, eps: 0.100\n",
      "Episode: 1820, Reward: 205.0, avg loss: 0.03684, eps: 0.100\n",
      "Episode: 1821, Reward: 150.0, avg loss: 0.04950, eps: 0.100\n",
      "Episode: 1822, Reward: 195.0, avg loss: 0.01693, eps: 0.100\n",
      "Episode: 1823, Reward: 135.0, avg loss: 0.02627, eps: 0.100\n",
      "Episode: 1824, Reward: 135.0, avg loss: 0.02482, eps: 0.100\n",
      "Episode: 1825, Reward: 95.0, avg loss: 0.01161, eps: 0.100\n",
      "Episode: 1826, Reward: 290.0, avg loss: 0.03364, eps: 0.100\n",
      "Episode: 1827, Reward: 200.0, avg loss: 0.04012, eps: 0.100\n",
      "Episode: 1828, Reward: 185.0, avg loss: 0.03449, eps: 0.100\n",
      "Episode: 1829, Reward: 160.0, avg loss: 0.02996, eps: 0.100\n",
      "Episode: 1830, Reward: 185.0, avg loss: 0.03035, eps: 0.100\n",
      "Episode: 1831, Reward: 205.0, avg loss: 0.02548, eps: 0.100\n",
      "Episode: 1832, Reward: 160.0, avg loss: 0.03260, eps: 0.100\n",
      "Episode: 1833, Reward: 60.0, avg loss: 0.01325, eps: 0.100\n",
      "Episode: 1834, Reward: 120.0, avg loss: 0.02509, eps: 0.100\n",
      "Episode: 1835, Reward: 250.0, avg loss: 0.02926, eps: 0.100\n",
      "Episode: 1836, Reward: 420.0, avg loss: 0.09702, eps: 0.100\n",
      "Episode: 1837, Reward: 255.0, avg loss: 0.03883, eps: 0.100\n",
      "Episode: 1838, Reward: 110.0, avg loss: 0.02580, eps: 0.100\n",
      "Episode: 1839, Reward: 110.0, avg loss: 0.01449, eps: 0.100\n",
      "Episode: 1840, Reward: 250.0, avg loss: 0.02710, eps: 0.100\n",
      "Episode: 1841, Reward: 300.0, avg loss: 0.02806, eps: 0.100\n",
      "Episode: 1842, Reward: 395.0, avg loss: 0.03885, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1843, Reward: 500.0, avg loss: 0.08318, eps: 0.100\n",
      "Episode: 1844, Reward: 80.0, avg loss: 0.00333, eps: 0.100\n",
      "Episode: 1845, Reward: 195.0, avg loss: 0.02290, eps: 0.100\n",
      "Episode: 1846, Reward: 145.0, avg loss: 0.03519, eps: 0.100\n",
      "Episode: 1847, Reward: 75.0, avg loss: 0.02461, eps: 0.100\n",
      "Episode: 1848, Reward: 215.0, avg loss: 0.03477, eps: 0.100\n",
      "Episode: 1849, Reward: 155.0, avg loss: 0.03079, eps: 0.100\n",
      "Episode: 1850, Reward: 105.0, avg loss: 0.02335, eps: 0.100\n",
      "Episode: 1851, Reward: 225.0, avg loss: 0.01823, eps: 0.100\n",
      "Episode: 1852, Reward: 125.0, avg loss: 0.03331, eps: 0.100\n",
      "Episode: 1853, Reward: 145.0, avg loss: 0.02277, eps: 0.100\n",
      "Episode: 1854, Reward: 215.0, avg loss: 0.03545, eps: 0.100\n",
      "Episode: 1855, Reward: 120.0, avg loss: 0.01864, eps: 0.100\n",
      "Episode: 1856, Reward: 105.0, avg loss: 0.01567, eps: 0.100\n",
      "Episode: 1857, Reward: 155.0, avg loss: 0.01271, eps: 0.100\n",
      "Episode: 1858, Reward: 330.0, avg loss: 0.04669, eps: 0.100\n",
      "Episode: 1859, Reward: 215.0, avg loss: 0.04106, eps: 0.100\n",
      "Episode: 1860, Reward: 685.0, avg loss: 0.06199, eps: 0.100\n",
      "Episode: 1861, Reward: 5.0, avg loss: 0.09947, eps: 0.100\n",
      "Episode: 1862, Reward: 55.0, avg loss: 0.03273, eps: 0.100\n",
      "Episode: 1863, Reward: 255.0, avg loss: 0.03119, eps: 0.100\n",
      "Episode: 1864, Reward: 160.0, avg loss: 0.02182, eps: 0.100\n",
      "Episode: 1865, Reward: 135.0, avg loss: 0.01772, eps: 0.100\n",
      "Episode: 1866, Reward: 255.0, avg loss: 0.06142, eps: 0.100\n",
      "Episode: 1867, Reward: 185.0, avg loss: 0.02721, eps: 0.100\n",
      "Episode: 1868, Reward: 150.0, avg loss: 0.01386, eps: 0.100\n",
      "Episode: 1869, Reward: 120.0, avg loss: 0.01981, eps: 0.100\n",
      "Episode: 1870, Reward: 125.0, avg loss: 0.03713, eps: 0.100\n",
      "Episode: 1871, Reward: 175.0, avg loss: 0.01423, eps: 0.100\n",
      "Episode: 1872, Reward: 185.0, avg loss: 0.02946, eps: 0.100\n",
      "Episode: 1873, Reward: 170.0, avg loss: 0.01744, eps: 0.100\n",
      "Episode: 1874, Reward: 440.0, avg loss: 0.04632, eps: 0.100\n",
      "Episode: 1875, Reward: 210.0, avg loss: 0.02162, eps: 0.100\n",
      "Episode: 1876, Reward: 145.0, avg loss: 0.01446, eps: 0.100\n",
      "Episode: 1877, Reward: 135.0, avg loss: 0.01888, eps: 0.100\n",
      "Episode: 1878, Reward: 80.0, avg loss: 0.04250, eps: 0.100\n",
      "Episode: 1879, Reward: 155.0, avg loss: 0.03303, eps: 0.100\n",
      "Episode: 1880, Reward: 210.0, avg loss: 0.03666, eps: 0.100\n",
      "Episode: 1881, Reward: 220.0, avg loss: 0.03038, eps: 0.100\n",
      "Episode: 1882, Reward: 235.0, avg loss: 0.04562, eps: 0.100\n",
      "Episode: 1883, Reward: 80.0, avg loss: 0.03835, eps: 0.100\n",
      "Episode: 1884, Reward: 565.0, avg loss: 0.04050, eps: 0.100\n",
      "Episode: 1885, Reward: 395.0, avg loss: 0.04356, eps: 0.100\n",
      "Episode: 1886, Reward: 210.0, avg loss: 0.04639, eps: 0.100\n",
      "Episode: 1887, Reward: 210.0, avg loss: 0.02640, eps: 0.100\n",
      "Episode: 1888, Reward: 110.0, avg loss: 0.02560, eps: 0.100\n",
      "Episode: 1889, Reward: 130.0, avg loss: 0.01202, eps: 0.100\n",
      "Episode: 1890, Reward: 255.0, avg loss: 0.02973, eps: 0.100\n",
      "Episode: 1891, Reward: 215.0, avg loss: 0.04990, eps: 0.100\n",
      "Episode: 1892, Reward: 240.0, avg loss: 0.04852, eps: 0.100\n",
      "Episode: 1893, Reward: 325.0, avg loss: 0.03791, eps: 0.100\n",
      "Episode: 1894, Reward: 205.0, avg loss: 0.02359, eps: 0.100\n",
      "Episode: 1895, Reward: 220.0, avg loss: 0.05309, eps: 0.100\n",
      "Episode: 1896, Reward: 445.0, avg loss: 0.03033, eps: 0.100\n",
      "Episode: 1897, Reward: 95.0, avg loss: 0.02820, eps: 0.100\n",
      "Episode: 1898, Reward: 200.0, avg loss: 0.04611, eps: 0.100\n",
      "Episode: 1899, Reward: 335.0, avg loss: 0.04036, eps: 0.100\n",
      "Episode: 1900, Reward: 150.0, avg loss: 0.03809, eps: 0.100\n",
      "Episode: 1901, Reward: 120.0, avg loss: 0.03089, eps: 0.100\n",
      "Episode: 1902, Reward: 55.0, avg loss: 0.01482, eps: 0.100\n",
      "Episode: 1903, Reward: 290.0, avg loss: 0.03534, eps: 0.100\n",
      "Episode: 1904, Reward: 110.0, avg loss: 0.01647, eps: 0.100\n",
      "Episode: 1905, Reward: 320.0, avg loss: 0.03188, eps: 0.100\n",
      "Episode: 1906, Reward: 230.0, avg loss: 0.04890, eps: 0.100\n",
      "Episode: 1907, Reward: 215.0, avg loss: 0.03308, eps: 0.100\n",
      "Episode: 1908, Reward: 75.0, avg loss: 0.02697, eps: 0.100\n",
      "Episode: 1909, Reward: 110.0, avg loss: 0.01304, eps: 0.100\n",
      "Episode: 1910, Reward: 220.0, avg loss: 0.04097, eps: 0.100\n",
      "Episode: 1911, Reward: 170.0, avg loss: 0.05040, eps: 0.100\n",
      "Episode: 1912, Reward: 215.0, avg loss: 0.02584, eps: 0.100\n",
      "Episode: 1913, Reward: 85.0, avg loss: 0.02676, eps: 0.100\n",
      "Episode: 1914, Reward: 105.0, avg loss: 0.04756, eps: 0.100\n",
      "Episode: 1915, Reward: 270.0, avg loss: 0.03626, eps: 0.100\n",
      "Episode: 1916, Reward: 155.0, avg loss: 0.02631, eps: 0.100\n",
      "Episode: 1917, Reward: 190.0, avg loss: 0.02940, eps: 0.100\n",
      "Episode: 1918, Reward: 200.0, avg loss: 0.02722, eps: 0.100\n",
      "Episode: 1919, Reward: 115.0, avg loss: 0.01813, eps: 0.100\n",
      "Episode: 1920, Reward: 140.0, avg loss: 0.01932, eps: 0.100\n",
      "Episode: 1921, Reward: 230.0, avg loss: 0.03047, eps: 0.100\n",
      "Episode: 1922, Reward: 150.0, avg loss: 0.02052, eps: 0.100\n",
      "Episode: 1923, Reward: 170.0, avg loss: 0.02199, eps: 0.100\n",
      "Episode: 1924, Reward: 90.0, avg loss: 0.01789, eps: 0.100\n",
      "Episode: 1925, Reward: 65.0, avg loss: 0.00628, eps: 0.100\n",
      "Episode: 1926, Reward: 290.0, avg loss: 0.02517, eps: 0.100\n",
      "Episode: 1927, Reward: 170.0, avg loss: 0.02744, eps: 0.100\n",
      "Episode: 1928, Reward: 410.0, avg loss: 0.04220, eps: 0.100\n",
      "Episode: 1929, Reward: 225.0, avg loss: 0.04730, eps: 0.100\n",
      "Episode: 1930, Reward: 185.0, avg loss: 0.03405, eps: 0.100\n",
      "Episode: 1931, Reward: 565.0, avg loss: 0.02355, eps: 0.100\n",
      "Episode: 1932, Reward: 165.0, avg loss: 0.09740, eps: 0.100\n",
      "Episode: 1933, Reward: 310.0, avg loss: 0.02301, eps: 0.100\n",
      "Episode: 1934, Reward: 170.0, avg loss: 0.03638, eps: 0.100\n",
      "Episode: 1935, Reward: 160.0, avg loss: 0.03047, eps: 0.100\n",
      "Episode: 1936, Reward: 60.0, avg loss: 0.01763, eps: 0.100\n",
      "Episode: 1937, Reward: 670.0, avg loss: 0.05102, eps: 0.100\n",
      "Episode: 1938, Reward: 40.0, avg loss: 0.01018, eps: 0.100\n",
      "Episode: 1939, Reward: 85.0, avg loss: 0.01305, eps: 0.100\n",
      "Episode: 1940, Reward: 230.0, avg loss: 0.01772, eps: 0.100\n",
      "Episode: 1941, Reward: 225.0, avg loss: 0.04020, eps: 0.100\n",
      "Episode: 1942, Reward: 575.0, avg loss: 0.05880, eps: 0.100\n",
      "Episode: 1943, Reward: 295.0, avg loss: 0.03717, eps: 0.100\n",
      "Episode: 1944, Reward: 190.0, avg loss: 0.03061, eps: 0.100\n",
      "Episode: 1945, Reward: 80.0, avg loss: 0.01507, eps: 0.100\n",
      "Episode: 1946, Reward: 115.0, avg loss: 0.01308, eps: 0.100\n",
      "Episode: 1947, Reward: 250.0, avg loss: 0.05018, eps: 0.100\n",
      "Episode: 1948, Reward: 485.0, avg loss: 0.08359, eps: 0.100\n",
      "Episode: 1949, Reward: 65.0, avg loss: 0.01032, eps: 0.100\n",
      "Episode: 1950, Reward: 60.0, avg loss: 0.01441, eps: 0.100\n",
      "Episode: 1951, Reward: 155.0, avg loss: 0.01928, eps: 0.100\n",
      "Episode: 1952, Reward: 180.0, avg loss: 0.03743, eps: 0.100\n",
      "Episode: 1953, Reward: 615.0, avg loss: 0.04124, eps: 0.100\n",
      "Episode: 1954, Reward: 325.0, avg loss: 0.06755, eps: 0.100\n",
      "Episode: 1955, Reward: 310.0, avg loss: 0.04046, eps: 0.100\n",
      "Episode: 1956, Reward: 215.0, avg loss: 0.03634, eps: 0.100\n",
      "Episode: 1957, Reward: 175.0, avg loss: 0.04622, eps: 0.100\n",
      "Episode: 1958, Reward: 230.0, avg loss: 0.05534, eps: 0.100\n",
      "Episode: 1959, Reward: 530.0, avg loss: 0.04789, eps: 0.100\n",
      "Episode: 1960, Reward: 160.0, avg loss: 0.03347, eps: 0.100\n",
      "Episode: 1961, Reward: 260.0, avg loss: 0.03455, eps: 0.100\n",
      "Episode: 1962, Reward: 425.0, avg loss: 0.04760, eps: 0.100\n",
      "Episode: 1963, Reward: 530.0, avg loss: 0.06965, eps: 0.100\n",
      "Episode: 1964, Reward: 150.0, avg loss: 0.03685, eps: 0.100\n",
      "Episode: 1965, Reward: 60.0, avg loss: 0.03359, eps: 0.100\n",
      "Episode: 1966, Reward: 75.0, avg loss: 0.02098, eps: 0.100\n",
      "Episode: 1967, Reward: 80.0, avg loss: 0.02842, eps: 0.100\n",
      "Episode: 1968, Reward: 75.0, avg loss: 0.02513, eps: 0.100\n",
      "Episode: 1969, Reward: 105.0, avg loss: 0.02465, eps: 0.100\n",
      "Episode: 1970, Reward: 115.0, avg loss: 0.02710, eps: 0.100\n",
      "Episode: 1971, Reward: 375.0, avg loss: 0.03570, eps: 0.100\n",
      "Episode: 1972, Reward: 130.0, avg loss: 0.02546, eps: 0.100\n",
      "Episode: 1973, Reward: 175.0, avg loss: 0.03260, eps: 0.100\n",
      "Episode: 1974, Reward: 215.0, avg loss: 0.04347, eps: 0.100\n",
      "Episode: 1975, Reward: 95.0, avg loss: 0.03367, eps: 0.100\n",
      "Episode: 1976, Reward: 195.0, avg loss: 0.01887, eps: 0.100\n",
      "Episode: 1977, Reward: 255.0, avg loss: 0.03140, eps: 0.100\n",
      "Episode: 1978, Reward: 210.0, avg loss: 0.03282, eps: 0.100\n",
      "Episode: 1979, Reward: 105.0, avg loss: 0.04164, eps: 0.100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1980, Reward: 180.0, avg loss: 0.03354, eps: 0.100\n",
      "Episode: 1981, Reward: 445.0, avg loss: 0.02557, eps: 0.100\n",
      "Episode: 1982, Reward: 200.0, avg loss: 0.02619, eps: 0.100\n",
      "Episode: 1983, Reward: 225.0, avg loss: 0.05085, eps: 0.100\n",
      "Episode: 1984, Reward: 210.0, avg loss: 0.05274, eps: 0.100\n",
      "Episode: 1985, Reward: 295.0, avg loss: 0.04228, eps: 0.100\n",
      "Episode: 1986, Reward: 125.0, avg loss: 0.01890, eps: 0.100\n",
      "Episode: 1987, Reward: 255.0, avg loss: 0.03036, eps: 0.100\n",
      "Episode: 1988, Reward: 375.0, avg loss: 0.04723, eps: 0.100\n",
      "Episode: 1989, Reward: 145.0, avg loss: 0.07136, eps: 0.100\n",
      "Episode: 1990, Reward: 215.0, avg loss: 0.02831, eps: 0.100\n",
      "Episode: 1991, Reward: 135.0, avg loss: 0.04882, eps: 0.100\n",
      "Episode: 1992, Reward: 495.0, avg loss: 0.05988, eps: 0.100\n",
      "Episode: 1993, Reward: 40.0, avg loss: 0.04390, eps: 0.100\n",
      "Episode: 1994, Reward: 140.0, avg loss: 0.01875, eps: 0.100\n",
      "Episode: 1995, Reward: 235.0, avg loss: 0.02621, eps: 0.100\n",
      "Episode: 1996, Reward: 325.0, avg loss: 0.05291, eps: 0.100\n",
      "Episode: 1997, Reward: 270.0, avg loss: 0.02466, eps: 0.100\n",
      "Episode: 1998, Reward: 120.0, avg loss: 0.01703, eps: 0.100\n",
      "Episode: 1999, Reward: 140.0, avg loss: 0.03516, eps: 0.100\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: primary_network.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "primary_network.save('primary_network.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('memory.pkl', 'wb') as output:\n",
    "    pickle.dump(memory, output, -1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9IIN5P24oT3T",
    "7cyM1FV5oYcN",
    "mvfzIEKdogTP",
    "d1fbQgmfoj6v"
   ],
   "name": "RL Project New.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
